{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vNqEMD4GoDHo"
   },
   "source": [
    "# 1. training data와 validation data에 label 붙여주기\n",
    "ImageGenerator 옵션에서 'shuffle = False'인 경우 지정 경로에서 alphanumeric order로 데이터가 입력됩니다. 그래서 먼저 alphanumeric으로 숫자를 정렬해주고, label을 붙여줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YLuH6whk9QzC"
   },
   "outputs": [],
   "source": [
    "##alphanumeric order\n",
    "def sort(lst): \n",
    "    lst = [str(i) for i in lst] \n",
    "    lst.sort() \n",
    "    lst = [int(i) if i.isdigit() else i for i in lst ] \n",
    "    return lst "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rmUwehKAmI0j"
   },
   "outputs": [],
   "source": [
    "## training data에 label 붙여주기\n",
    "\n",
    "ls = []\n",
    "for i in range(756):\n",
    "    ls.append(i)\n",
    "num_list = sort(ls)\n",
    "\n",
    "wheel_imgs_num = {}\n",
    "\n",
    "for idx in num_list:\n",
    "    wheel_img_path = glob.glob('training set 저장경로/%s/*.jpeg' % idx) ## %s 부분에 이름 숫자인 폴더가 들어감 \n",
    "    wheel_imgs_num[idx] = len(wheel_img_path)\n",
    "\n",
    "label_trained = np.array([], dtype ='int32')\n",
    "for idx in wheel_imgs_num:\n",
    "    x = np.array([idx]*wheel_imgs_num[idx], dtype ='int32')\n",
    "    label_trained = np.concatenate((label_trained,x))\n",
    "label_trained\n",
    "\n",
    "nb_train_samples = len(label_trained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PH4rA9-zefM7"
   },
   "outputs": [],
   "source": [
    "ls = []\n",
    "for i in range(756):\n",
    "    ls.append(i)\n",
    "num_list = sort(ls)\n",
    "\n",
    "wheel_imgs_num = {}\n",
    "\n",
    "for idx in num_list:\n",
    "    wheel_img_path = glob.glob('validation set 저장경로/%s/*.jpeg' % idx) ## %s 부분에 이름 숫자인 폴더가 들어감 \n",
    "    wheel_imgs_num[idx] = len(wheel_img_path)\n",
    "\n",
    "label_validate = np.array([], dtype ='int32')\n",
    "for idx in wheel_imgs_num:\n",
    "    x = np.array([idx]*wheel_imgs_num[idx], dtype ='int32')\n",
    "    label_validate = np.concatenate((label_validate,x))\n",
    "label_validate\n",
    "\n",
    "nb_validation_samples = len(label_validate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5MJlRwKu_uvJ"
   },
   "source": [
    "#2. Transfer Learning 1 : ResNet50 계층 그대로 가져다 쓰기\n",
    "전이학습에는 계층을 그대로 가져다 쓰는 방법과, 계층 중에서 일부를 더 학습시키는 방법(fine-tuning)이 있습니다. 첫 번째 방법은 분류기를 제외한 사전 학습된 모델을 가져온 다음 그 위에 사용자에게 맞게 fully-connected 계층을 얹어서 모델을 구축합니다. 기존 예제코드에서 돌려볼 수 있는 부분은 돌려보면서 바로 사용할 수 있게끔 만들었습니다.\n",
    "\n",
    "참고 : https://keraskorea.github.io/posts/2018-10-24-little_data_powerful_model/ <- 케라스 공식 블로그, 작은 데이터셋으로 강력한 이미지 분류 모델 설계하기\n",
    "\n",
    "https://gist.github.com/fchollet/f35fbc80e066a49d65f1688a7e99f069 <- 참고한 원본 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2Ph9fKOjk3fp"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras import applications\n",
    "from keras.callbacks import EarlyStopping, LambdaCallback\n",
    " \n",
    "\n",
    "\n",
    "# dimensions of our images.\n",
    "img_width, img_height = 224, 224 ##프로젝트 활용 이미지의 크기\n",
    "\n",
    "top_model_weights_path = 'top_model이 저장될 경로'\n",
    "train_data_dir = 'training data의 경로'\n",
    "validation_data_dir = 'validation data의 경로'\n",
    "nb_train_samples = len(label_trained)\n",
    "nb_validation_samples = len(label_validate)\n",
    "epochs = 50 ## 학습 에폭 수\n",
    "batch_size = 1500 ## 학습 당 batch_size\n",
    "\n",
    "## bottleneck_features : classifier 직전의 vector를 의미함. (ResNet 50을 통과시킨) feature vector와 같은 의미\n",
    "def save_bottlebeck_features():\n",
    "    datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "    # build the ResNet50 Network\n",
    "    model = applications.ResNet50(include_top=False, weights='imagenet')\n",
    "    # Shuffle을 false로 두어야 원래 순서대로 들어감(카테고리가 뒤섞이지 않는다.)\n",
    "    generator = datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,\n",
    "        shuffle=False)\n",
    "    bottleneck_features_train = model.predict_generator(\n",
    "        generator)\n",
    "    # np.save / np.load : 경로 지정한 곳으로 저장, 불러오기 가능, .npy확장자로 save하면 batch로 묶인 벡터들이 들어간다.\n",
    "    np.save('저장 원하는 경로/bottleneck_features_train.npy',\n",
    "            bottleneck_features_train)\n",
    "\n",
    "    generator = datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,\n",
    "        shuffle=False)\n",
    "    bottleneck_features_validation = model.predict_generator(\n",
    "        generator)\n",
    "    np.save('저장 원하는 경로/bottleneck_features_validation.npy',\n",
    "            bottleneck_features_validation)\n",
    "\n",
    "    # 위에서 저장한 feature vector들을 불러와서, 순서대로 들어온 feature vector들에 label을 붙여준다.\n",
    "def train_top_model():\n",
    "    train_data = np.load('저장경로/bottleneck_features_train.npy')\n",
    "    train_labels = label_trained\n",
    "\n",
    "    validation_data = np.load('저장경로/bottleneck_features_validation.npy')\n",
    "    validation_labels = label_validate\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=train_data.shape[1:]))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(756, activation='softmax')) #dense는 분류기 갯수만큼\n",
    "\n",
    "    model.compile(optimizer='rmsprop',\n",
    "                  loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    print_weights = LambdaCallback(on_epoch_end=lambda epoch, logs: print(model.layers[3].get_weights()))\n",
    "    early_stopping = EarlyStopping(patience=3, mode='auto', monitor='val_loss')\n",
    "\n",
    "    model.fit(train_data, train_labels,\n",
    "              epochs=epochs,\n",
    "              batch_size=batch_size,\n",
    "              validation_data=(validation_data, validation_labels),\n",
    "              callbacks=[early_stopping, print_weights])\n",
    "    model.save_weights(top_model_weights_path)\n",
    "\n",
    "\n",
    "save_bottlebeck_features()\n",
    "train_top_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hPiIzWXjARWu"
   },
   "source": [
    "#3. Transfer Learning 2 : ResNet50 계층 일부분을 추가로 학습시켜서 활용하기(Fine-tuning)\n",
    "기존에 학습되어있는 fully-connected 계층을 가져와서(위에서 학습시킨 모델 가중치) ResNet50 위에 얹습니다. 이후 ResNet50 계층 구조를 참고하여 학습시키지 않을 부분은 동결시키고(non-trainable) 학습시킬 부분만 살려서 학습을 진행합니다.(중간에 non-trainable 계층 갯수는 생각해봐야 할 부분) 참고 페이지에서도 말하듯 fine tuning의 핵심은 미세 조정이기 때문에 learning rate를 낮게 설정하고, 또한 사례에서는 모델의 마지막 계층만을 추가로 학습시켰습니다.\n",
    "\n",
    "참고 : https://keraskorea.github.io/posts/2018-10-24-little_data_powerful_model/ <- 케라스 공식 블로그, 작은 데이터셋으로 강력한 이미지 분류(Transfer Learning 1과 동일)\n",
    "\n",
    "https://gist.github.com/fchollet/7eb39b44eb9e16e59632d25fb3119975 <- 원본 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 474,
     "status": "error",
     "timestamp": 1592394620943,
     "user": {
      "displayName": "‍박세웅[학생](경영대학 경영학과)",
      "photoUrl": "",
      "userId": "02497672298865538770"
     },
     "user_tz": -540
    },
    "id": "_8t7tjpxAX-p",
    "outputId": "a3eaa599-3292-4593-ea4a-f3467a26556a"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-25-48f69a2b8133>\"\u001b[0;36m, line \u001b[0;32m16\u001b[0m\n\u001b[0;31m    nb_train_samples = ##데이터 갯수에 맞춰서\u001b[0m\n\u001b[0m                                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "\n",
    "# path to the model weights files.\n",
    "## top_model_weights : 얹기 전에 미리 학습을 시켜야 함, 위에서 학습한 모델 가중치 활용\n",
    "top_model_weights_path = 'top model의 weights 있는 경로' ## 먼저 학습을 시키고 weight를 저장해둬야 함.\n",
    "# dimensions of our images.\n",
    "img_width, img_height = 224, 224\n",
    "\n",
    "train_data_dir = 'training data의 경로'\n",
    "validation_data_dir = 'validation data의 경로'\n",
    "nb_train_samples = len(label_trained) \n",
    "nb_validation_samples = len(label_validate)\n",
    "epochs = 50\n",
    "batch_size = 1500\n",
    "\n",
    "# build the ResNet50 network(사용자에 맞게)\n",
    "model = applications.ResNet50(weights='imagenet', include_top=False)\n",
    "print('Model loaded.')\n",
    "\n",
    "# build a classifier model to put on top of the convolutional model\n",
    "top_model = Sequential()\n",
    "top_model.add(Flatten(input_shape=model.output_shape[1:]))\n",
    "top_model.add(Dense(256, activation='relu'))\n",
    "top_model.add(Dropout(0.5))\n",
    "top_model.add(Dense(756, activation='softmax'))\n",
    "\n",
    "# note that it is necessary to start with a fully-trained\n",
    "# classifier, including the top classifier,\n",
    "# in order to successfully do fine-tuning\n",
    "top_model.load_weights(top_model_weights_path)\n",
    "\n",
    "# add the model on top of the convolutional base\n",
    "model.add(top_model)\n",
    "\n",
    "## ResNet50 기준으로 conv5(마지막 convolution layer)만 살리고 나머지는 동결\n",
    "for layer in model.layers[:143]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# compile the model with a SGD/momentum optimizer\n",
    "# and a very slow learning rate.\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Generator로 데이터 준비\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "print_weights = LambdaCallback(on_epoch_end=lambda epoch, logs: print(model.layers[3].get_weights()))\n",
    "early_stopping = EarlyStopping(patience=3, mode='auto', monitor='val_loss')\n",
    "# fine-tune the model\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    callbacks=[early_stopping, print_weights])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPqoiC7yYLW5na13+/pnv4u",
   "collapsed_sections": [],
   "mount_file_id": "1f8pLSAYqumuggQSEp_x7vlZK1qPCVRcB",
   "name": "Transfer Learning_최종.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
