{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\seohyeonpark\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\seohyeonpark\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\seohyeonpark\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\seohyeonpark\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\seohyeonpark\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\seohyeonpark\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\seohyeonpark\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\seohyeonpark\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\seohyeonpark\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\seohyeonpark\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\seohyeonpark\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\seohyeonpark\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "#@title Imports and function definitions\n",
    "\n",
    "# For running inference on the TF-Hub module.\n",
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "# For downloading the image.\n",
    "import matplotlib.pyplot as plt\n",
    "import tempfile\n",
    "from six.moves.urllib.request import urlopen\n",
    "from six import BytesIO\n",
    "\n",
    "# For drawing onto the image.\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from PIL import ImageColor\n",
    "from PIL import ImageDraw\n",
    "from PIL import ImageFont\n",
    "from PIL import ImageOps\n",
    "\n",
    "# For measuring the inference time.\n",
    "import time\n",
    "\n",
    "#\n",
    "import cv2\n",
    "# from google.colab.patches import cv2_imshow\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "# 모듈 불러오기 / #@param은 colab환경에서 콤보박스로 모델하나 선택할 수 있게끔 해주는 거\n",
    "# 여기에 사용할 모델 찾아서 쓰면 될 듯. 앞서 말했듯이 이 부분을 직접 훈련시켜야 할 수도 있을 것 같음\n",
    "module_handle = \"https://tfhub.dev/google/openimages_v4/ssd/mobilenet_v2/1\" #@param [\"https://tfhub.dev/google/openimages_v4/ssd/mobilenet_v2/1\"]\n",
    "detector = hub.load(module_handle).signatures['default']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions Preparing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 바운딩 박스 좌표 함수\n",
    "# Adds a bounding box to an image.\n",
    "def draw_bounding_box_on_image(image,\n",
    "                               ymin,\n",
    "                               xmin,\n",
    "                               ymax,\n",
    "                               xmax,\n",
    "                               color,\n",
    "                               font,\n",
    "                               thickness=4,\n",
    "                               display_str_list=()):\n",
    "\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    im_width, im_height = image.size\n",
    "\n",
    "    # 좌표 지정\n",
    "    (left, right, top, bottom) = (xmin * im_width, xmax * im_width,\n",
    "                                ymin * im_height, ymax * im_height)\n",
    "        # xmin, xmax, ymin, ymax는 0부터 1사이 값이여야겠네\n",
    "    draw.line([(left, top), (left, bottom), (right, bottom), (right, top),\n",
    "             (left, top)],\n",
    "            width=thickness,\n",
    "            fill=color)\n",
    "\n",
    "    # If the total height of the display strings added to the top of the bounding\n",
    "    # box exceeds the top of the image, stack the strings below the bounding box\n",
    "    # instead of above.\n",
    "    display_str_heights = [font.getsize(ds)[1] for ds in display_str_list]\n",
    "    # Each display_str has a top and bottom margin of 0.05x. 끄트머리에 0.05만큼 더 공간이 있음\n",
    "    total_display_str_height = (1 + 2 * 0.05) * sum(display_str_heights)\n",
    "      #  1.1 * sum\n",
    "\n",
    "    if top > total_display_str_height:\n",
    "        text_bottom = top\n",
    "    else:\n",
    "        text_bottom = top + total_display_str_height\n",
    "    # Reverse list and print from bottom to top.\n",
    "    for display_str in display_str_list[::-1]:\n",
    "        text_width, text_height = font.getsize(display_str)\n",
    "        margin = np.ceil(0.05 * text_height)\n",
    "        draw.rectangle([(left, text_bottom - text_height - 2 * margin),\n",
    "                        (left + text_width, text_bottom)],\n",
    "                       fill=color)\n",
    "        draw.text((left + margin, text_bottom - text_height - margin),\n",
    "                  display_str,\n",
    "                  fill=\"black\",\n",
    "                  font=font)\n",
    "        text_bottom -= text_height - 2 * margin\n",
    "\n",
    "\n",
    "# 바운딩 박스 그리기 함수\n",
    "def draw_boxes(image, boxes, class_names, scores, max_boxes=10, min_score=0.1):\n",
    "  # draw_boxes(img.numpy(), result[\"detection_boxes\"],result[\"detection_class_entities\"], result[\"detection_scores\"]\n",
    "    \"\"\"Overlay labeled boxes on an image with formatted scores and label names.\"\"\"\n",
    "    colors = list(ImageColor.colormap.values())\n",
    "\n",
    "    try:\n",
    "        font = ImageFont.truetype(\"/usr/share/fonts/truetype/liberation/LiberationSansNarrow-Regular.ttf\",\n",
    "                                  25)\n",
    "    except IOError:\n",
    "        print(\"Font not found, using default font.\")\n",
    "        font = ImageFont.load_default()\n",
    "\n",
    "    for i in range(min(boxes.shape[0], max_boxes)):\n",
    "        if scores[i] >= min_score: #scores[i] = result[\"detection_scores\"][i]\n",
    "            ymin, xmin, ymax, xmax = tuple(boxes[i])\n",
    "            display_str = \"{}: {}%\".format(class_names[i].decode(\"ascii\"),\n",
    "                                         int(100 * scores[i]))\n",
    "            color = colors[hash(class_names[i]) % len(colors)]\n",
    "              # 그냥 colors 리스트에서 각 객체마다 색을 지정하는 방법\n",
    "              # hash('객체명') : 입력값 별로 같은 값이 나오도록 암호화 시켜주는 함수\n",
    "            image_pil = Image.fromarray(np.uint8(image)).convert(\"RGB\")\n",
    "            draw_bounding_box_on_image(\n",
    "              image_pil,\n",
    "              ymin,\n",
    "              xmin,\n",
    "              ymax,\n",
    "              xmax,\n",
    "              color,\n",
    "              font,\n",
    "              display_str_list=[display_str])\n",
    "            np.copyto(image, np.array(image_pil))\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 로드 함수\n",
    "def load_img(path):\n",
    "    img = tf.io.read_file(path)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 보여주기 함수\n",
    "def display_image(image):\n",
    "    fig = plt.figure(figsize=(20, 15))\n",
    "    # figsize(float, float), optional, default: None\n",
    "    #   width, height in inches.\n",
    "    #   If not provided, defaults to rcParams[\"figure.figsize\"] (default: [6.4, 4.8]) = [6.4, 4.8].\n",
    "    plt.grid(False)\n",
    "    # 이 함수는 그래프 내에 그리드를 그려주는 함수\n",
    "    # gird(b=None, which = 'major', axis = 'both', **kwargs)\n",
    "    #   b : grid를 작성할지 안할지 결정, **kwargs가 입력됐다면 자동으로 b인자를 True로 받는다.\n",
    "    #   which : major, minor, both 중 어느 틱에 대한 그리드를 그릴지 설정\n",
    "    #   axis : x축, y축, both에 그리드를 그리도록 설정\n",
    "    plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Cropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "Wheel Object Detection \n",
    "\n",
    "1. detector \n",
    "''' \n",
    "\n",
    "class wheel:\n",
    "    # 클래스 내외에서 사용할 변수 지정하기\n",
    "    # 크래스명(혹은 인스턴스명).변수명으로 불러올 수 있음 \n",
    "    img_url = \"\" # 해당 이미지 url\n",
    "    img = [] # 해당 이미지 배열\n",
    "\n",
    "    box_location = np.array([]) # 탐지된 객체의 left right top bottom 좌표 비율\n",
    "    # (전체 width와 height의 비율로 나타남, 0과 1사이값, 위의 draw_boxes의 x_min, x_max, y_min, y_max와 같다고 생각하면 됨)\n",
    "    approx_location = () # 탐지된 객체의 left right top bottom 픽셀 위치 좌표\n",
    "    detection_class_entities = np.array([]) # 탐지된 객체 레이블명\n",
    "    detection_scores= np.array([]) # 탐지 정확도\n",
    "\n",
    "    cropped_image = [] #도려낸 이미지 저장\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    # 1. 휠의 바운딩 박스 좌표 비율(box_location 찾기)\n",
    "    def wheel_location(self, detector, path):\n",
    "        wheel.img_url = path\n",
    "        wheel.img = load_img(path)\n",
    "        converted_img  = tf.image.convert_image_dtype(wheel.img, tf.float32)[tf.newaxis, ...]\n",
    "        start_time = time.time()\n",
    "        result = detector(converted_img)\n",
    "        end_time = time.time()\n",
    "\n",
    "        result = {key:value.numpy() for key,value in result.items()}\n",
    "    \n",
    "    # 휠만 뽑아내기!\n",
    "      # 모델에 있는 모든 레이블 값(car, window 등)이 아닌 그중에 휠 정보만 뽑아내기 위해서\n",
    "        wheel_result = {} # result 중에 휠에 대한 정보만 담을 딕셔너리\n",
    "        for key in result.keys():\n",
    "            wheel_result[key] = np.array([]) # result와 같은 key 생성, value는 빈 np.array값으로\n",
    "\n",
    "        for i in range(len(result['detection_boxes'])): # result의 객체 수 만큼 반복\n",
    "            if result['detection_class_labels'][i] == 409: # 휠 일련번호가 409인 경우에만 정보 추출\n",
    "                if len(wheel_result['detection_class_entities']) == 0: # 처음 정보를 입력할 경우\n",
    "                    for key in wheel_result.keys():\n",
    "                        wheel_result[key] = np.array([result[key][i]])\n",
    "\n",
    "            else :                                                 # 두 번째 부터는\n",
    "                if wheel_result[\"detection_scores\"][0] < result['detection_scores'][i]:\n",
    "                    for key in result.keys():\n",
    "                        wheel_result[key]  = np.array([result[key][i]])\n",
    "\n",
    "#    print(\"Found %d objects.\" % len(wheel_result[\"detection_scores\"]))\n",
    "#    print(\"Inference time: \", end_time-start_time)\n",
    "\n",
    "        wheel.box_location = wheel_result[\"detection_boxes\"]\n",
    "        wheel.detection_class_entities = wheel_result['detection_class_entities']\n",
    "        wheel.detection_scores= wheel_result['detection_scores']\n",
    "\n",
    "\n",
    "# 2. 휠의 정확한 좌표 찾기 (approx_location)\n",
    "    # 상대적 위치 x (width or height)\n",
    "    def box_area(self):\n",
    "        where_box = wheel.box_location[0]\n",
    "\n",
    "        # 이미지 가로, 세로 길이\n",
    "        width = wheel.img.shape[1]\n",
    "        height = wheel.img.shape[0]\n",
    "\n",
    "        # 박스 좌표\n",
    "        top = where_box[0]*height\n",
    "        bottom = where_box[2]*height\n",
    "        left = where_box[1]*width\n",
    "        right = where_box[3]*width\n",
    "\n",
    "        wheel.approx_location = (left, top, right, bottom)\n",
    "\n",
    "\n",
    "# 3. 이미지 도려내기\n",
    "    def crop_image(self):\n",
    "        img = Image.open(wheel.img_url)\n",
    "        #   img= img.convert('L') # 흑백사진으로 바꾸고 싶으면 이용\n",
    "        cropped_image = img.crop(wheel.approx_location)\n",
    "        return cropped_image\n",
    "    '''\n",
    "# 4. 도려낸 이미지 음영 제거하기\n",
    "  def Homomorphic(self):\n",
    "    ### homomorphic filter는 gray scale image에 대해서 밖에 안 되므로\n",
    "    ### YUV color space로 converting한 뒤 Y에 대해 연산을 진행\n",
    "    img = wheel.cropped_image \n",
    "    img_YUV = cv2.cvtColor(img, cv2.COLOR_BGR2YUV)    \n",
    "    y = img_YUV[:,:,0]    \n",
    "    \n",
    "    rows = y.shape[0]    \n",
    "    cols = y.shape[1]\n",
    "    \n",
    "    ### illumination elements와 reflectance elements를 분리하기 위해 log를 취함\n",
    "    imgLog = np.log1p(np.array(y, dtype='float') / 255) # y값을 0~1사이로 조정한 뒤 log(x+1)\n",
    "    \n",
    "    ### frequency를 이미지로 나타내면 4분면에 대칭적으로 나타나므로 \n",
    "    ### 4분면 중 하나에 이미지를 대응시키기 위해 row와 column을 2배씩 늘려줌\n",
    "    M = 2*rows + 1\n",
    "    N = 2*cols + 1\n",
    "    \n",
    "    ### gaussian mask 생성 sigma = 10\n",
    "    sigma = 10\n",
    "    (X, Y) = np.meshgrid(np.linspace(0, N-1, N), np.linspace(0, M-1, M)) # 0~N-1(and M-1) 까지 1단위로 space를 만듬\n",
    "    Xc = np.ceil(N/2) # 올림 연산\n",
    "    Yc = np.ceil(M/2)\n",
    "    gaussianNumerator = (X - Xc)**2 + (Y - Yc)**2 # 가우시안 분자 생성\n",
    "    \n",
    "    ### low pass filter와 high pass filter 생성\n",
    "    LPF = np.exp(-gaussianNumerator / (2*sigma*sigma))\n",
    "    HPF = 1 - LPF\n",
    "    \n",
    "    ### LPF랑 HPF를 0이 가운데로 오도록iFFT함. \n",
    "    ### 사실 이 부분이 잘 이해가 안 가는데 plt로 이미지를 띄워보니 shuffling을 수행한 효과가 났음\n",
    "    ### 에너지를 각 귀퉁이로 모아 줌\n",
    "    LPF_shift = np.fft.ifftshift(LPF.copy())\n",
    "    HPF_shift = np.fft.ifftshift(HPF.copy())\n",
    "    \n",
    "    ### Log를 씌운 이미지를 FFT해서 LPF와 HPF를 곱해 LF성분과 HF성분을 나눔\n",
    "    img_FFT = np.fft.fft2(imgLog.copy(), (M, N))\n",
    "    img_LF = np.real(np.fft.ifft2(img_FFT.copy() * LPF_shift, (M, N)) # low frequency 성분\n",
    "    img_HF = np.real(np.fft.ifft2(img_FFT.copy() * HPF_shift, (M, N)) # high frequency 성분\n",
    "    \n",
    "    ### 각 LF, HF 성분에 scaling factor를 곱해주어 조명값과 반사값을 조절함\n",
    "    gamma1 = 0.3\n",
    "    gamma2 = 1.5\n",
    "    img_adjusting = gamma1*img_LF[0:rows, 0:cols] + gamma2*img_HF[0:rows, 0:cols]\n",
    "    \n",
    "    ### 조정된 데이터를 이제 exp 연산을 통해 이미지로 만들어줌\n",
    "    img_exp = np.expm1(img_adjusting) # exp(x) + 1\n",
    "    img_exp = (img_exp - np.min(img_exp)) / (np.max(img_exp) - np.min(img_exp)) # 0~1사이로 정규화\n",
    "    img_out = np.array(255*img_exp, dtype = 'uint8') # 255를 곱해서 intensity값을 만들어줌\n",
    "    \n",
    "    ### 마지막으로 YUV에서 Y space를 filtering된 이미지로 교체해주고 RGB space로 converting\n",
    "    img_YUV[:,:,0] = img_out\n",
    "    result = cv2.cvtColor(img_YUV, cv2.COLOR_YUV2BGR)\n",
    "    final\n",
    "    '''\n",
    "\n",
    "\n",
    "# 4. 휠 이미지만 찾아 보여주기\n",
    "    def A_wheel_in_a_box(self):\n",
    "        image_with_boxes = draw_boxes(\n",
    "            wheel.img.numpy(), wheel.box_location,\n",
    "            wheel.detection_class_entities, wheel.detection_scores)\n",
    "\n",
    "        display_image(image_with_boxes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 휠만 골라내기 과정\n",
    "\n",
    "0. 이미지 url \n",
    "\n",
    "1. 인스턴스 객체 생성\n",
    "\n",
    "  finding_wheel = wheel() \n",
    "\n",
    "\n",
    "2. 휠 박스 위치, 이미지 저장\n",
    "\n",
    "  finding_wheel.A_wheel_location(detector, 이미지 url)\n",
    "\n",
    "  finding_wheel.box_coordinates()\n",
    "\n",
    "\n",
    "3. 휠 이미지만 도려내기\n",
    "\n",
    "  cropped_image = finding_wheel.crop_image()\n",
    "\n",
    "4. 이미지 저장하기\n",
    "\n",
    "cropped_image.save(value[:-9]+'wheel_'+value[-9:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_list = glob.glob(\"C:/Users/seohyeonpark/Desktop/netcarshow2015_서현/*.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-92ee1c6937b5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;31m# bounding box 위치 찾기\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mfinding_wheel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwheel_location\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdetector\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# 상대적 위치\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[1;32mtry\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mfinding_wheel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapprox_location\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-19-5cc10df60798>\u001b[0m in \u001b[0;36mwheel_location\u001b[1;34m(self, detector, path)\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[0mend_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalue\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[1;31m# 휠만 뽑아내기!\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-19-5cc10df60798>\u001b[0m in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[0mend_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalue\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[1;31m# 휠만 뽑아내기!\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'numpy'"
     ]
    }
   ],
   "source": [
    "# 휠 사진 추출하기\n",
    "i = 1\n",
    "for img in img_list[1] :\n",
    "    # index = values.index(value)\n",
    "    # 객체 생성\n",
    "    finding_wheel = wheel()\n",
    "\n",
    "    # bounding box 위치 찾기\n",
    "    finding_wheel.wheel_location(detector, img) # 상대적 위치\n",
    "    try :\n",
    "        finding_wheel.approx_location()\n",
    "    except: # 보통 사진에서 휠을 찾지 못한 경우 에러가 발생\n",
    "        print(str(i) + \"번째 반복에서 휠을 찾지 못했습니다.\")\n",
    "        continue\n",
    "\n",
    "    # 이미지 도려내기\n",
    "    cropped_image = finding_wheel.crop_image()\n",
    "\n",
    "    # 도려낸거 보여줘\n",
    "    #display_image(cropped_image)\n",
    "\n",
    "    # 이미지 저장\n",
    "    download_path = str('C:/Users/seohyeonpark/Desktop/wheel' + \"/wheel\" + img.split('/')[-1] + str(i))\n",
    "    cropped_image.save(download_path)\n",
    "\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
