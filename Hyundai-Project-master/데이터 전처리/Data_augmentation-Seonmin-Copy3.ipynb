{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 먼저 tensorflow GPU 확인!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 11011498139758127047\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 3059430195\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 3295971302436839120\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1650, pci bus id: 0000:01:00.0, compute capability: 7.5\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op MatMul in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "tf.Tensor(\n",
      "[[22. 28.]\n",
      " [49. 64.]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "# 텐서 생성\n",
    "a = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "b = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\n",
    "c = tf.matmul(a, b)\n",
    "\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "UnknownError",
     "evalue": "Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. [Op:Conv2D]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-5015d7bf872f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;31m# We run each op once to warm up; see: https://stackoverflow.com/a/45067900\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m \u001b[0mgpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;31m# Run the op several times.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-5015d7bf872f>\u001b[0m in \u001b[0;36mgpu\u001b[1;34m()\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/device:GPU:0'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0mrandom_image_gpu\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m224\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m224\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m         \u001b[0mnet_gpu\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_image_gpu\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet_gpu\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\wheel-similarity\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    820\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[0;32m    821\u001b[0m               self._compute_dtype):\n\u001b[1;32m--> 822\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    823\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    824\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\wheel-similarity\\lib\\site-packages\\tensorflow_core\\python\\keras\\layers\\convolutional.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    207\u001b[0m       \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_causal_padding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 209\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_convolution_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    210\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\wheel-similarity\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inp, filter)\u001b[0m\n\u001b[0;32m   1133\u001b[0m           call_from_convolution=False)\n\u001b[0;32m   1134\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1135\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1136\u001b[0m     \u001b[1;31m# copybara:strip_end\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m     \u001b[1;31m# copybara:insert return self.conv_op(inp, filter)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\wheel-similarity\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inp, filter)\u001b[0m\n\u001b[0;32m    638\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    639\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=redefined-builtin\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 640\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    641\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    642\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\wheel-similarity\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inp, filter)\u001b[0m\n\u001b[0;32m    237\u001b[0m         \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    238\u001b[0m         \u001b[0mdata_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 239\u001b[1;33m         name=self.name)\n\u001b[0m\u001b[0;32m    240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\wheel-similarity\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36mconv2d\u001b[1;34m(input, filter, strides, padding, use_cudnn_on_gpu, data_format, dilations, name, filters)\u001b[0m\n\u001b[0;32m   2009\u001b[0m                            \u001b[0mdata_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2010\u001b[0m                            \u001b[0mdilations\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdilations\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2011\u001b[1;33m                            name=name)\n\u001b[0m\u001b[0;32m   2012\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2013\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\wheel-similarity\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_nn_ops.py\u001b[0m in \u001b[0;36mconv2d\u001b[1;34m(input, filter, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name)\u001b[0m\n\u001b[0;32m    931\u001b[0m             \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstrides\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m             \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexplicit_paddings\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexplicit_paddings\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 933\u001b[1;33m             data_format=data_format, dilations=dilations, name=name, ctx=_ctx)\n\u001b[0m\u001b[0;32m    934\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_SymbolicException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m         \u001b[1;32mpass\u001b[0m  \u001b[1;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\wheel-similarity\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_nn_ops.py\u001b[0m in \u001b[0;36mconv2d_eager_fallback\u001b[1;34m(input, filter, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name, ctx)\u001b[0m\n\u001b[0;32m   1020\u001b[0m   explicit_paddings, \"data_format\", data_format, \"dilations\", dilations)\n\u001b[0;32m   1021\u001b[0m   _result = _execute.execute(b\"Conv2D\", 1, inputs=_inputs_flat, attrs=_attrs,\n\u001b[1;32m-> 1022\u001b[1;33m                              ctx=ctx, name=name)\n\u001b[0m\u001b[0;32m   1023\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0m_execute\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmust_record_gradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1024\u001b[0m     _execute.record_gradient(\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\wheel-similarity\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m     \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m     keras_symbolic_tensors = [\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\wheel-similarity\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mUnknownError\u001b[0m: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. [Op:Conv2D]"
     ]
    }
   ],
   "source": [
    "#%tensorflow_version 2.x\n",
    "import tensorflow as tf\n",
    "import timeit\n",
    "\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "    print(\n",
    "      '\\n\\nThis error most likely means that this notebook is not '\n",
    "      'configured to use a GPU.  Change this in Notebook Settings via the '\n",
    "      'command palette (cmd/ctrl-shift-P) or the Edit menu.\\n\\n')\n",
    "    raise SystemError('GPU device not found')\n",
    "\n",
    "def cpu():\n",
    "    with tf.device('/cpu:0'):\n",
    "        random_image_cpu = tf.random.normal((200,224,224,3))\n",
    "        net_cpu = tf.keras.layers.Conv2D(32, 7)(random_image_cpu)\n",
    "        return tf.math.reduce_sum(net_cpu)\n",
    "\n",
    "def gpu():\n",
    "    with tf.device('/device:GPU:0'):\n",
    "        random_image_gpu = tf.random.normal((200,224,224,3))\n",
    "        net_gpu = tf.keras.layers.Conv2D(32, 7)(random_image_gpu)\n",
    "    return tf.math.reduce_sum(net_gpu)\n",
    "  \n",
    "# We run each op once to warm up; see: https://stackoverflow.com/a/45067900\n",
    "cpu()\n",
    "gpu()\n",
    "\n",
    "# Run the op several times.\n",
    "print('Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images '\n",
    "      '(batch x height x width x channel). Sum of ten runs.')\n",
    "print('CPU (s):')\n",
    "cpu_time = timeit.timeit('cpu()', number=10, setup=\"from __main__ import cpu\")\n",
    "print(cpu_time)\n",
    "print('GPU (s):')\n",
    "gpu_time = timeit.timeit('gpu()', number=10, setup=\"from __main__ import gpu\")\n",
    "print(gpu_time)\n",
    "print('GPU speedup over CPU: {}x'.format(int(cpu_time/gpu_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GlYQGKif1T4h"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "from PIL import Image\n",
    "from numpy import expand_dims\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 이진화 전처리 함수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "세웅이 모델에 들어가는 이미지 형태는 최종 BGR이여야 함!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1, 원본 그대로~\n",
    "\n",
    "\n",
    "def original(imgpath):\n",
    "    img = load_img(img_path)\n",
    "    img = img_to_array(img)\n",
    "    bgr_image = cv2.cvtColor(img,cv2.COLOR_RGB2BGR)\n",
    "    return bgr_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adaptive threshold만 적용\n",
    "def threshold(imgpath):\n",
    "    # grayscale 변환\n",
    "    img = load_img(imgpath)\n",
    "    img = img_to_array(img)\n",
    "    gray_image = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY) #(a,b) -> 2차원으로 변환\n",
    "    gray_image = gray_image.astype('uint8')\n",
    "    \n",
    "    # adaptive threshold 적용\n",
    "    th = cv2.adaptiveThreshold(gray_image,\n",
    "                               255,\n",
    "                               cv2.ADAPTIVE_THRESH_GAUSSIAN_C, \n",
    "                               cv2.THRESH_BINARY,\n",
    "                               99,\n",
    "                               15)\n",
    "    \n",
    "    # bgr 변환\n",
    "    bgr_image = cv2.cvtColor(th,cv2.COLOR_GRAY2BGR)\n",
    "    return bgr_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# morph gradient\n",
    "def morphology(imgpath):\n",
    "    # grayscale 변환\n",
    "    img = load_img(imgpath)\n",
    "    img = img_to_array(img)\n",
    "    gray_image = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY) #(a,b) -> 2차원으로 변환\n",
    "    gray_image = gray_image.astype('uint8')\n",
    "    \n",
    "    # morphgradient 적용\n",
    "    kernel = np.ones((2,2), np.uint8)\n",
    "    img_grad = cv2.morphologyEx(gray_image, cv2.MORPH_GRADIENT, kernel)\n",
    "    \n",
    "    # bgr로 변환\n",
    "    bgr_image = cv2.cvtColor(img_grad,cv2.COLOR_GRAY2BGR)\n",
    "    return bgr_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 대비 향상 -> adaptive threshold\n",
    "def threshold_sole(imgpath):\n",
    "    # grayscale 변환\n",
    "    img = load_img(imgpath)\n",
    "    img = img_to_array(img)\n",
    "    gray_image = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY) #(a,b) -> 2차원으로 변환\n",
    "    gray_image = gray_image.astype('uint8')\n",
    "    \n",
    "    # 이미지 대비를 향상\n",
    "    image_enhanced = cv2.equalizeHist(gray_image)\n",
    "    \n",
    "    # Adaptive Thresholding 적용 \n",
    "    max_output_value = 255   # 출력 픽셀 강도의 최대값\n",
    "    neighborhood_size = 99\n",
    "    subtract_from_mean = 15\n",
    "    image_binarized = cv2.adaptiveThreshold(image_enhanced,\n",
    "                                          255,\n",
    "                                          cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                          cv2.THRESH_BINARY,\n",
    "                                          99,\n",
    "                                          15)\n",
    "    \n",
    "    # bgr 변환\n",
    "    bgr_image = cv2.cvtColor(image_binarized,cv2.COLOR_GRAY2BGR)  \n",
    "    return bgr_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# morphology -> adaptive threshold\n",
    "def morph_threshold(imgpath):\n",
    "    # graysacle\n",
    "    img = load_img(imgpath)\n",
    "    img = img_to_array(img)\n",
    "    gray_image = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    gray_image = gray_image.astype('uint8')\n",
    "    \n",
    "    # morph gradient\n",
    "    kernel = np.ones((2,2), np.uint8)\n",
    "    img2_grad = cv2.morphologyEx(gray_image, cv2.MORPH_GRADIENT, kernel)\n",
    "    \n",
    "    # adaptive threshold\n",
    "    th = cv2.adaptiveThreshold(img2_grad, \n",
    "                               255, \n",
    "                               cv2.ADAPTIVE_THRESH_GAUSSIAN_C, \n",
    "                               cv2.THRESH_BINARY,\n",
    "                               99,\n",
    "                               15)\n",
    "    \n",
    "    # bgr 변환\n",
    "    bgr_image = cv2.cvtColor(th,cv2.COLOR_GRAY2BGR) # result함수 돌리기 위해 3차원으로 변환 \n",
    "    return bgr_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# morph_gradient -> 이미지 대비 향상 -> adaptive threshold\n",
    "def morph_threshold_sole(imgpath):\n",
    "    #grayscale\n",
    "    img = load_img(imgpath)\n",
    "    img = img_to_array(img)\n",
    "    gray_image = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    gray_image = gray_image.astype('uint8')\n",
    "    \n",
    "    # 이미지 대비를 향상\n",
    "    image_enhanced = cv2.equalizeHist(gray_image)\n",
    "    \n",
    "    # morph_gradient\n",
    "    kernel = np.ones((2,2), np.uint8)\n",
    "    img2_grad = cv2.morphologyEx(image_enhanced, cv2.MORPH_GRADIENT, kernel)\n",
    "    \n",
    "    # Adaptive Thresholding 적용 \n",
    "    image_binarized = cv2.adaptiveThreshold(img2_grad,\n",
    "                                          255,\n",
    "                                          cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                          cv2.THRESH_BINARY,\n",
    "                                          99,\n",
    "                                          15)\n",
    "    \n",
    "    # bgr 변환\n",
    "    bgr_image = cv2.cvtColor(image_binarized,cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    \n",
    "    return bgr_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 원본 이미지 경로 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 카테고리 재분류한 폴더 경로\n",
    "folder_path = \"C:/Users/seohyeonpark/프로젝트/튜닝스타 카테고리 재분류\"\n",
    "\n",
    "# 코드에 맞게 이름 변경해서 생성할 폴더 경로\n",
    "new_folder_path = \"C:/Users/seohyeonpark/프로젝트/TuningStar2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2, 93):\n",
    "    i_images = glob.glob(folder_path + '/새 폴더 (' + str(i) + ')/*.jpg' )\n",
    "    \n",
    "    j = 0\n",
    "    for path in i_images:\n",
    "        category_num = i-2\n",
    "        img_name = str(category_num) + \" (\" + str(j) + \").jpg\"\n",
    "        to_folder_path = new_folder_path + '/' + img_name\n",
    "        shutil.copy(path, to_folder_path)\n",
    "        j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories_with_a_image = glob.glob(folder_path + '/새 폴더/*.jpg' )\n",
    "\n",
    "category_num = 91\n",
    "for path in categories_with_a_image:\n",
    "    img_name = str(category_num) + \".jpg\"\n",
    "    to_folder_path = new_folder_path + '/' + img_name\n",
    "    shutil.copy(path, to_folder_path)\n",
    "    category_num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_img_pathes = glob.glob(\"C:/Users/seohyeonpark/프로젝트/TuningStar2/*.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:/Users/seohyeonpark/프로젝트/TuningStar2\\\\0 (0).jpg',\n",
       " 'C:/Users/seohyeonpark/프로젝트/TuningStar2\\\\0 (1).jpg',\n",
       " 'C:/Users/seohyeonpark/프로젝트/TuningStar2\\\\0 (2).jpg',\n",
       " 'C:/Users/seohyeonpark/프로젝트/TuningStar2\\\\0 (3).jpg',\n",
       " 'C:/Users/seohyeonpark/프로젝트/TuningStar2\\\\1 (0).jpg']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 경로 확인\n",
    "my_img_pathes[:5] # '서현' 로컬 컴퓨터에서는 주소 마지막에 \\\\ 뜸.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 주소 정상적으로 불러지면 이 셀은 건너 뛰어도 됨\n",
    "i = 0\n",
    "for path in my_img_pathes:\n",
    "    path = path.replace('\\\\','/')\n",
    "    my_img_pathes[i] = path\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:/Users/seohyeonpark/프로젝트/TuningStar2/0 (0).jpg',\n",
       " 'C:/Users/seohyeonpark/프로젝트/TuningStar2/0 (1).jpg',\n",
       " 'C:/Users/seohyeonpark/프로젝트/TuningStar2/0 (2).jpg',\n",
       " 'C:/Users/seohyeonpark/프로젝트/TuningStar2/0 (3).jpg',\n",
       " 'C:/Users/seohyeonpark/프로젝트/TuningStar2/1 (0).jpg']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_img_pathes[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "621"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(my_img_pathes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 분류할 카테고리 넘버 리스트, 딕셔너리 만들기\n",
    "#### category_nums, category_count_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4RrVCjcM6Oe2"
   },
   "outputs": [],
   "source": [
    "category_nums=[]\n",
    "for img_path in my_img_pathes:\n",
    "    num_jpg = img_path.split(\"/\")[-1] # 휠 파일 이름.jpg\n",
    "    category_num = num_jpg.split('.')[0] # jpg 떼어 버리기!\n",
    "    try:\n",
    "        category_num = int(category_num) # (i)번 째 안되어 있으면 바로 정수형으로 바꿔잇!\n",
    "    except:\n",
    "        if \"(\" in category_num: # (i)번째 표시되어있으면 날리고 앞에 카테고리만 저장\n",
    "            category_num = int(category_num.split(\"(\")[0])\n",
    "        elif \"-\" in category_num: # - i 로 표시한 사람것도 날리고 앞에 카테고리만 저장\n",
    "            category_num = int(category_num.split('-')[0])\n",
    "    category_nums.append(category_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 18,\n",
       " 18,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 2,\n",
       " 2,\n",
       " 20,\n",
       " 20,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 22,\n",
       " 22,\n",
       " 23,\n",
       " 23,\n",
       " 23,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 25,\n",
       " 25,\n",
       " 25,\n",
       " 26,\n",
       " 26,\n",
       " 27,\n",
       " 27,\n",
       " 27,\n",
       " 28,\n",
       " 28,\n",
       " 28,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 3,\n",
       " 3,\n",
       " 30,\n",
       " 30,\n",
       " 31,\n",
       " 31,\n",
       " 31,\n",
       " 31,\n",
       " 32,\n",
       " 32,\n",
       " 32,\n",
       " 33,\n",
       " 33,\n",
       " 33,\n",
       " 34,\n",
       " 34,\n",
       " 35,\n",
       " 35,\n",
       " 35,\n",
       " 35,\n",
       " 35,\n",
       " 35,\n",
       " 35,\n",
       " 35,\n",
       " 35,\n",
       " 35,\n",
       " 35,\n",
       " 35,\n",
       " 35,\n",
       " 35,\n",
       " 35,\n",
       " 35,\n",
       " 35,\n",
       " 35,\n",
       " 35,\n",
       " 35,\n",
       " 35,\n",
       " 35,\n",
       " 35,\n",
       " 35,\n",
       " 35,\n",
       " 35,\n",
       " 35,\n",
       " 35,\n",
       " 35,\n",
       " 35,\n",
       " 35,\n",
       " 35,\n",
       " 35,\n",
       " 35,\n",
       " 35,\n",
       " 35,\n",
       " 35,\n",
       " 35,\n",
       " 35,\n",
       " 35,\n",
       " 35,\n",
       " 35,\n",
       " 35,\n",
       " 36,\n",
       " 36,\n",
       " 36,\n",
       " 37,\n",
       " 37,\n",
       " 37,\n",
       " 37,\n",
       " 37,\n",
       " 37,\n",
       " 37,\n",
       " 37,\n",
       " 37,\n",
       " 37,\n",
       " 37,\n",
       " 37,\n",
       " 37,\n",
       " 37,\n",
       " 37,\n",
       " 38,\n",
       " 38,\n",
       " 38,\n",
       " 38,\n",
       " 38,\n",
       " 38,\n",
       " 38,\n",
       " 38,\n",
       " 38,\n",
       " 38,\n",
       " 39,\n",
       " 39,\n",
       " 39,\n",
       " 39,\n",
       " 39,\n",
       " 39,\n",
       " 39,\n",
       " 39,\n",
       " 39,\n",
       " 39,\n",
       " 39,\n",
       " 39,\n",
       " 39,\n",
       " 39,\n",
       " 39,\n",
       " 39,\n",
       " 39,\n",
       " 39,\n",
       " 39,\n",
       " 39,\n",
       " 39,\n",
       " 4,\n",
       " 4,\n",
       " 40,\n",
       " 40,\n",
       " 40,\n",
       " 40,\n",
       " 40,\n",
       " 40,\n",
       " 40,\n",
       " 40,\n",
       " 40,\n",
       " 40,\n",
       " 40,\n",
       " 40,\n",
       " 40,\n",
       " 40,\n",
       " 40,\n",
       " 40,\n",
       " 40,\n",
       " 40,\n",
       " 40,\n",
       " 40,\n",
       " 40,\n",
       " 40,\n",
       " 40,\n",
       " 40,\n",
       " 40,\n",
       " 40,\n",
       " 40,\n",
       " 40,\n",
       " 40,\n",
       " 40,\n",
       " 40,\n",
       " 40,\n",
       " 41,\n",
       " 41,\n",
       " 41,\n",
       " 41,\n",
       " 41,\n",
       " 41,\n",
       " 41,\n",
       " 41,\n",
       " 41,\n",
       " 41,\n",
       " 41,\n",
       " 41,\n",
       " 41,\n",
       " 41,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 43,\n",
       " 43,\n",
       " 43,\n",
       " 43,\n",
       " 43,\n",
       " 43,\n",
       " 43,\n",
       " 43,\n",
       " 43,\n",
       " 43,\n",
       " 44,\n",
       " 44,\n",
       " 44,\n",
       " 45,\n",
       " 45,\n",
       " 45,\n",
       " 45,\n",
       " 45,\n",
       " 45,\n",
       " 45,\n",
       " 46,\n",
       " 46,\n",
       " 47,\n",
       " 47,\n",
       " 47,\n",
       " 47,\n",
       " 47,\n",
       " 48,\n",
       " 48,\n",
       " 48,\n",
       " 48,\n",
       " 48,\n",
       " 48,\n",
       " 48,\n",
       " 48,\n",
       " 48,\n",
       " 48,\n",
       " 48,\n",
       " 49,\n",
       " 49,\n",
       " 49,\n",
       " 49,\n",
       " 49,\n",
       " 49,\n",
       " 49,\n",
       " 49,\n",
       " 49,\n",
       " 49,\n",
       " 49,\n",
       " 49,\n",
       " 49,\n",
       " 49,\n",
       " 49,\n",
       " 49,\n",
       " 49,\n",
       " 49,\n",
       " 49,\n",
       " 49,\n",
       " 49,\n",
       " 49,\n",
       " 49,\n",
       " 49,\n",
       " 49,\n",
       " 49,\n",
       " 49,\n",
       " 49,\n",
       " 49,\n",
       " 49,\n",
       " 49,\n",
       " 49,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 50,\n",
       " 50,\n",
       " 50,\n",
       " 50,\n",
       " 51,\n",
       " 51,\n",
       " 51,\n",
       " 51,\n",
       " 51,\n",
       " 51,\n",
       " 51,\n",
       " 51,\n",
       " 52,\n",
       " 52,\n",
       " 52,\n",
       " 52,\n",
       " 53,\n",
       " 53,\n",
       " 53,\n",
       " 53,\n",
       " 54,\n",
       " 54,\n",
       " 54,\n",
       " 55,\n",
       " 55,\n",
       " 56,\n",
       " 56,\n",
       " 56,\n",
       " 57,\n",
       " 57,\n",
       " 57,\n",
       " 57,\n",
       " 58,\n",
       " 58,\n",
       " 58,\n",
       " 59,\n",
       " 59,\n",
       " 59,\n",
       " 59,\n",
       " 59,\n",
       " 59,\n",
       " 59,\n",
       " 59,\n",
       " 59,\n",
       " 59,\n",
       " 59,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 60,\n",
       " 60,\n",
       " 60,\n",
       " 60,\n",
       " 60,\n",
       " 60,\n",
       " 60,\n",
       " 60,\n",
       " 60,\n",
       " 60,\n",
       " 60,\n",
       " 60,\n",
       " 60,\n",
       " 60,\n",
       " 60,\n",
       " 60,\n",
       " 60,\n",
       " 60,\n",
       " 60,\n",
       " 60,\n",
       " 60,\n",
       " 60,\n",
       " 60,\n",
       " 60,\n",
       " 60,\n",
       " 60,\n",
       " 60,\n",
       " 60,\n",
       " 60,\n",
       " 60,\n",
       " 60,\n",
       " 60,\n",
       " 60,\n",
       " 60,\n",
       " 60,\n",
       " 60,\n",
       " 60,\n",
       " 61,\n",
       " 61,\n",
       " 61,\n",
       " 61,\n",
       " 61,\n",
       " 61,\n",
       " 61,\n",
       " 61,\n",
       " 61,\n",
       " 61,\n",
       " 61,\n",
       " 62,\n",
       " 62,\n",
       " 62,\n",
       " 62,\n",
       " 62,\n",
       " 62,\n",
       " 62,\n",
       " 62,\n",
       " 62,\n",
       " 62,\n",
       " 62,\n",
       " 62,\n",
       " 62,\n",
       " 62,\n",
       " 62,\n",
       " 62,\n",
       " 62,\n",
       " 62,\n",
       " 62,\n",
       " 62,\n",
       " 62,\n",
       " 62,\n",
       " 62,\n",
       " 62,\n",
       " 62,\n",
       " 62,\n",
       " 62,\n",
       " 62,\n",
       " 62,\n",
       " 62,\n",
       " 62,\n",
       " 62,\n",
       " 62,\n",
       " 62,\n",
       " 62,\n",
       " 62,\n",
       " 62,\n",
       " 62,\n",
       " 62,\n",
       " 62,\n",
       " 62,\n",
       " 62,\n",
       " 62,\n",
       " 62,\n",
       " 62,\n",
       " 62,\n",
       " 62,\n",
       " 62,\n",
       " 62,\n",
       " 62,\n",
       " 62,\n",
       " 62,\n",
       " 63,\n",
       " 63,\n",
       " 63,\n",
       " 64,\n",
       " 64,\n",
       " 64,\n",
       " 64,\n",
       " 64,\n",
       " 64,\n",
       " 64,\n",
       " 64,\n",
       " 64,\n",
       " 64,\n",
       " 65,\n",
       " 65,\n",
       " 66,\n",
       " 66,\n",
       " 66,\n",
       " 67,\n",
       " 67,\n",
       " 68,\n",
       " 68,\n",
       " 69,\n",
       " 69,\n",
       " 69,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 70,\n",
       " 70,\n",
       " 71,\n",
       " 71,\n",
       " 71,\n",
       " 71,\n",
       " 71,\n",
       " 72,\n",
       " 72,\n",
       " 72,\n",
       " 72,\n",
       " 73,\n",
       " 73,\n",
       " 73,\n",
       " 73,\n",
       " 73,\n",
       " 73,\n",
       " 74,\n",
       " 74,\n",
       " 75,\n",
       " 75,\n",
       " 76,\n",
       " 76,\n",
       " 76,\n",
       " 77,\n",
       " 77,\n",
       " 78,\n",
       " 78,\n",
       " 79,\n",
       " 79,\n",
       " 79,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 80,\n",
       " 80,\n",
       " 81,\n",
       " 81,\n",
       " 82,\n",
       " 82,\n",
       " 82,\n",
       " 83,\n",
       " 83,\n",
       " 84,\n",
       " 84,\n",
       " 85,\n",
       " 85,\n",
       " 86,\n",
       " 86,\n",
       " 87,\n",
       " 87,\n",
       " 88,\n",
       " 88,\n",
       " 89,\n",
       " 89,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 90,\n",
       " 90]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_nums"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2Dt2HwB_SHFn"
   },
   "source": [
    "각 카테고리 번호 별로 몇 개씩 들어있는 지 카운팅한 뒤, 카테고리(key):등장횟수(value) 형태로 딕셔너리 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R8TDl9w2_GXI"
   },
   "outputs": [],
   "source": [
    "category_count_dict = {}\n",
    "for i in range(len(category_nums)):\n",
    "    num_count = category_nums.count(i)\n",
    "    category_count_dict[i] = num_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_list = []\n",
    "for value in category_count_dict.values():\n",
    "    if value not in count_list:\n",
    "        count_list.append(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prime_number(number):\n",
    "    if number != 1:\n",
    "        for f in range(2, number):\n",
    "            if number % f == 0:\n",
    "                return False\n",
    "    else:\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 3, 2, 14, 22, 5, 12, 7, 6, 11, 43, 15, 10, 21, 32, 19, 8, 37, 52, 0]\n"
     ]
    }
   ],
   "source": [
    "print(count_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  3  2  0  0  5  0  7  0 11 43  0  0  0  0 19  0 37  0  0]\n",
      "20\n",
      "[False, True, True, False, False, True, False, True, False, True, True, False, False, False, False, True, False, True, False, True]\n"
     ]
    }
   ],
   "source": [
    "count = []\n",
    "for i in count_list:\n",
    "    count.append(prime_number(i))\n",
    "print(np.array(count) * np.array(count_list))\n",
    "print(len(count))\n",
    "print(count)# 소수 : 2, 3, 5, 7 -> 다 곱하면 210"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69828990"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2*3*5*7*11*43*19*37"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5Ux2t2mqSAI2"
   },
   "source": [
    "Keras의 ImageDataGenerator를 통해 Data Augmentation을 할 수 있는 generator생성."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qxGJA1qa1fQx"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "## data augmentation\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.applications import Xception\n",
    "from keras.utils import multi_gpu_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/device:GPU:0'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 각 전처리 방법으로 이진화 후 다른 폴더에 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C8v-ISjqSZv1"
   },
   "source": [
    "배정받은 이미지 경로들을 통해 이미지를 가져오고,\n",
    "하나의 카테고리를 하나의 폴더로 만듦. 위에서도 이야기했듯이 파일 번호 = 카테고리이므로 이미 카테고리 폴더가 생성되어있는 경우는 넘어가게 햇음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하나의 이미지에 대해 파일 이름, 카테고리 인덱스, 같은 카테고리로 분류된 이미지의 개수 반환해주는 함수\n",
    "def count_category(img_path, category_count_dict):\n",
    "    # 1. 파일 이름(img_name)\n",
    "    num_jpg = img_path.split(\"/\")[-1] # 이미지 경로 마지막 (휠 번호.jpg) 만 떼어내기\n",
    "    category_num = num_jpg.split('.')[0] # .jpg떼어 버리기! (휠 번호.jpg) -> (휠 번호)\n",
    "    img_name = category_num\n",
    "    \n",
    "    # 2. 카테고리 인덱스(category_num)\n",
    "    try:\n",
    "        '''\n",
    "        카테고리 번호만 category_num에 저장하도록 한다 -> 나중에 augmentation한 폴더 이름 설정할 때 사용\n",
    "        현재 img_name은 1 or 1 (1) or 1-1 형식으로 되어있음.\n",
    "        맨 앞에 카테고리 분류한 숫자에만 관심이 있기 때문에\n",
    "        먼저 1과 같이 같은 카테고리 내에 한 개의 이미지만 있는 경우는 int(category_num)으로 숫자 추출,\n",
    "        에러가 발생한다면 \"(\", \")\",\"-\" 등이 category_num에 포함되어 있는 것이기 때문에,\n",
    "        각 문장부호 들로 split 후 맨 앞에 카테고리 분류 숫자를 반환\n",
    "        '''\n",
    "        category_num = int(category_num) # (i)번 째 안되어 있으면 바로 정수형으로 바꿔잇!\n",
    "    except:\n",
    "        if \"(\" in category_num: # (i)번째 표시되어있으면 날리고 앞에 카테고리만 저장\n",
    "            category_num = int(category_num.split(\"(\")[0])\n",
    "        elif \"-\" in category_num: # - i 로 표시한 사람것도 날리고 앞에 카테고리만 저장\n",
    "            category_num = int(category_num.split('-')[0])\n",
    "    \n",
    "    # 3. 같은 카테고리로 분류된 이미지의 개수(category_count)\n",
    "    category_count = category_count_dict[category_num] # 해당 이미지의 카테고리에 몇개의 이미지가 있는가\n",
    "    return img_name, category_count, category_num\n",
    "\n",
    "# 이미지 전처리 함수\n",
    "#: 앞서 정해준 이진화 방법들 중 하나를 function에 넣어주면 이미지를 해당 방법으로 이진화 후 \n",
    "def preprocess(img_path, function):\n",
    "    img = function(img_path) # function에 전처리 함수를 넣어 해당 방법으로 전처리한다.\n",
    "    x = expand_dims(img,0) # 차원 추가\n",
    "    return x\n",
    "\n",
    "def augmentation(x):\n",
    "    with tf.device('/device:GPU:0'):\n",
    "        data = datagen.flow(x,\n",
    "                            batch_size=1,\n",
    "                            save_to_dir=folder_path,\n",
    "                            save_prefix=category_num,\n",
    "                            save_format=\"jpeg\")\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 478
    },
    "colab_type": "code",
    "id": "gz_D3luq9Pyr",
    "outputId": "88cdd47b-d578-4b8c-84d5-2e03f5807633",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 _category count :  4\n",
      "0 _aug_num :  450\n",
      "0 _category count :  4\n",
      "0 _aug_num :  450\n",
      "0 _category count :  4\n",
      "0 _aug_num :  450\n",
      "0 _category count :  4\n",
      "0 _aug_num :  450\n",
      "1 _category count :  3\n",
      "1 _aug_num :  600\n",
      "1 _category count :  3\n",
      "1 _aug_num :  600\n",
      "1 _category count :  3\n",
      "1 _aug_num :  600\n",
      "10 _category count :  12\n",
      "10 _aug_num :  150\n",
      "10 _category count :  12\n",
      "10 _aug_num :  150\n",
      "10 _category count :  12\n",
      "10 _aug_num :  150\n",
      "10 _category count :  12\n",
      "10 _aug_num :  150\n",
      "10 _category count :  12\n",
      "10 _aug_num :  150\n",
      "10 _category count :  12\n",
      "10 _aug_num :  150\n",
      "10 _category count :  12\n",
      "10 _aug_num :  150\n",
      "10 _category count :  12\n",
      "10 _aug_num :  150\n",
      "10 _category count :  12\n",
      "10 _aug_num :  150\n",
      "10 _category count :  12\n",
      "10 _aug_num :  150\n",
      "10 _category count :  12\n",
      "10 _aug_num :  150\n",
      "10 _category count :  12\n",
      "10 _aug_num :  150\n",
      "11 _category count :  4\n",
      "11 _aug_num :  450\n",
      "11 _category count :  4\n",
      "11 _aug_num :  450\n",
      "11 _category count :  4\n",
      "11 _aug_num :  450\n",
      "11 _category count :  4\n",
      "11 _aug_num :  450\n",
      "12 _category count :  7\n",
      "12 _aug_num :  257\n",
      "12 _category count :  7\n",
      "12 _aug_num :  257\n",
      "12 _category count :  7\n",
      "12 _aug_num :  257\n",
      "12 _category count :  7\n",
      "12 _aug_num :  257\n",
      "12 _category count :  7\n",
      "12 _aug_num :  257\n",
      "12 _category count :  7\n",
      "12 _aug_num :  257\n",
      "12 _category count :  7\n",
      "12 _aug_num :  257\n",
      "13 _category count :  3\n",
      "13 _aug_num :  600\n",
      "13 _category count :  3\n",
      "13 _aug_num :  600\n",
      "13 _category count :  3\n",
      "13 _aug_num :  600\n",
      "14 _category count :  6\n",
      "14 _aug_num :  300\n",
      "14 _category count :  6\n",
      "14 _aug_num :  300\n",
      "14 _category count :  6\n",
      "14 _aug_num :  300\n",
      "14 _category count :  6\n",
      "14 _aug_num :  300\n",
      "14 _category count :  6\n",
      "14 _aug_num :  300\n",
      "14 _category count :  6\n",
      "14 _aug_num :  300\n",
      "15 _category count :  11\n",
      "15 _aug_num :  163\n",
      "15 _category count :  11\n",
      "15 _aug_num :  163\n",
      "15 _category count :  11\n",
      "15 _aug_num :  163\n",
      "15 _category count :  11\n",
      "15 _aug_num :  163\n",
      "15 _category count :  11\n",
      "15 _aug_num :  163\n",
      "15 _category count :  11\n",
      "15 _aug_num :  163\n",
      "15 _category count :  11\n",
      "15 _aug_num :  163\n",
      "15 _category count :  11\n",
      "15 _aug_num :  163\n",
      "15 _category count :  11\n",
      "15 _aug_num :  163\n",
      "15 _category count :  11\n",
      "15 _aug_num :  163\n",
      "15 _category count :  11\n",
      "15 _aug_num :  163\n",
      "16 _category count :  11\n",
      "16 _aug_num :  163\n",
      "16 _category count :  11\n",
      "16 _aug_num :  163\n",
      "16 _category count :  11\n",
      "16 _aug_num :  163\n",
      "16 _category count :  11\n",
      "16 _aug_num :  163\n",
      "16 _category count :  11\n",
      "16 _aug_num :  163\n",
      "16 _category count :  11\n",
      "16 _aug_num :  163\n",
      "16 _category count :  11\n",
      "16 _aug_num :  163\n",
      "16 _category count :  11\n",
      "16 _aug_num :  163\n",
      "16 _category count :  11\n",
      "16 _aug_num :  163\n",
      "16 _category count :  11\n",
      "16 _aug_num :  163\n",
      "16 _category count :  11\n",
      "16 _aug_num :  163\n",
      "17 _category count :  6\n",
      "17 _aug_num :  300\n",
      "17 _category count :  6\n",
      "17 _aug_num :  300\n",
      "17 _category count :  6\n",
      "17 _aug_num :  300\n",
      "17 _category count :  6\n",
      "17 _aug_num :  300\n",
      "17 _category count :  6\n",
      "17 _aug_num :  300\n",
      "17 _category count :  6\n",
      "17 _aug_num :  300\n",
      "18 _category count :  2\n",
      "18 _aug_num :  900\n",
      "18 _category count :  2\n",
      "18 _aug_num :  900\n",
      "19 _category count :  4\n",
      "19 _aug_num :  450\n",
      "19 _category count :  4\n",
      "19 _aug_num :  450\n",
      "19 _category count :  4\n",
      "19 _aug_num :  450\n",
      "19 _category count :  4\n",
      "19 _aug_num :  450\n",
      "2 _category count :  2\n",
      "2 _aug_num :  900\n",
      "2 _category count :  2\n",
      "2 _aug_num :  900\n",
      "20 _category count :  2\n",
      "20 _aug_num :  900\n",
      "20 _category count :  2\n",
      "20 _aug_num :  900\n",
      "21 _category count :  4\n",
      "21 _aug_num :  450\n",
      "21 _category count :  4\n",
      "21 _aug_num :  450\n",
      "21 _category count :  4\n",
      "21 _aug_num :  450\n",
      "21 _category count :  4\n",
      "21 _aug_num :  450\n",
      "22 _category count :  2\n",
      "22 _aug_num :  900\n",
      "22 _category count :  2\n",
      "22 _aug_num :  900\n",
      "23 _category count :  3\n",
      "23 _aug_num :  600\n",
      "23 _category count :  3\n",
      "23 _aug_num :  600\n",
      "23 _category count :  3\n",
      "23 _aug_num :  600\n",
      "24 _category count :  3\n",
      "24 _aug_num :  600\n",
      "24 _category count :  3\n",
      "24 _aug_num :  600\n",
      "24 _category count :  3\n",
      "24 _aug_num :  600\n",
      "25 _category count :  3\n",
      "25 _aug_num :  600\n",
      "25 _category count :  3\n",
      "25 _aug_num :  600\n",
      "25 _category count :  3\n",
      "25 _aug_num :  600\n",
      "26 _category count :  2\n",
      "26 _aug_num :  900\n",
      "26 _category count :  2\n",
      "26 _aug_num :  900\n",
      "27 _category count :  3\n",
      "27 _aug_num :  600\n",
      "27 _category count :  3\n",
      "27 _aug_num :  600\n",
      "27 _category count :  3\n",
      "27 _aug_num :  600\n",
      "28 _category count :  3\n",
      "28 _aug_num :  600\n",
      "28 _category count :  3\n",
      "28 _aug_num :  600\n",
      "28 _category count :  3\n",
      "28 _aug_num :  600\n",
      "29 _category count :  3\n",
      "29 _aug_num :  600\n",
      "29 _category count :  3\n",
      "29 _aug_num :  600\n",
      "29 _category count :  3\n",
      "29 _aug_num :  600\n",
      "3 _category count :  2\n",
      "3 _aug_num :  900\n",
      "3 _category count :  2\n",
      "3 _aug_num :  900\n",
      "30 _category count :  2\n",
      "30 _aug_num :  900\n",
      "30 _category count :  2\n",
      "30 _aug_num :  900\n",
      "31 _category count :  4\n",
      "31 _aug_num :  450\n",
      "31 _category count :  4\n",
      "31 _aug_num :  450\n",
      "31 _category count :  4\n",
      "31 _aug_num :  450\n",
      "31 _category count :  4\n",
      "31 _aug_num :  450\n",
      "32 _category count :  3\n",
      "32 _aug_num :  600\n",
      "32 _category count :  3\n",
      "32 _aug_num :  600\n",
      "32 _category count :  3\n",
      "32 _aug_num :  600\n",
      "33 _category count :  3\n",
      "33 _aug_num :  600\n",
      "33 _category count :  3\n",
      "33 _aug_num :  600\n",
      "33 _category count :  3\n",
      "33 _aug_num :  600\n",
      "34 _category count :  2\n",
      "34 _aug_num :  900\n",
      "34 _category count :  2\n",
      "34 _aug_num :  900\n",
      "35 _category count :  43\n",
      "35 _aug_num :  41\n",
      "35 _category count :  43\n",
      "35 _aug_num :  41\n",
      "35 _category count :  43\n",
      "35 _aug_num :  41\n",
      "35 _category count :  43\n",
      "35 _aug_num :  41\n",
      "35 _category count :  43\n",
      "35 _aug_num :  41\n",
      "35 _category count :  43\n",
      "35 _aug_num :  41\n",
      "35 _category count :  43\n",
      "35 _aug_num :  41\n",
      "35 _category count :  43\n",
      "35 _aug_num :  41\n",
      "35 _category count :  43\n",
      "35 _aug_num :  41\n",
      "35 _category count :  43\n",
      "35 _aug_num :  41\n",
      "35 _category count :  43\n",
      "35 _aug_num :  41\n",
      "35 _category count :  43\n",
      "35 _aug_num :  41\n",
      "35 _category count :  43\n",
      "35 _aug_num :  41\n",
      "35 _category count :  43\n",
      "35 _aug_num :  41\n",
      "35 _category count :  43\n",
      "35 _aug_num :  41\n",
      "35 _category count :  43\n",
      "35 _aug_num :  41\n",
      "35 _category count :  43\n",
      "35 _aug_num :  41\n",
      "35 _category count :  43\n",
      "35 _aug_num :  41\n",
      "35 _category count :  43\n",
      "35 _aug_num :  41\n",
      "35 _category count :  43\n",
      "35 _aug_num :  41\n",
      "35 _category count :  43\n",
      "35 _aug_num :  41\n",
      "35 _category count :  43\n",
      "35 _aug_num :  41\n",
      "35 _category count :  43\n",
      "35 _aug_num :  41\n",
      "35 _category count :  43\n",
      "35 _aug_num :  41\n",
      "35 _category count :  43\n",
      "35 _aug_num :  41\n",
      "35 _category count :  43\n",
      "35 _aug_num :  41\n",
      "35 _category count :  43\n",
      "35 _aug_num :  41\n",
      "35 _category count :  43\n",
      "35 _aug_num :  41\n",
      "35 _category count :  43\n",
      "35 _aug_num :  41\n",
      "35 _category count :  43\n",
      "35 _aug_num :  41\n",
      "35 _category count :  43\n",
      "35 _aug_num :  41\n",
      "35 _category count :  43\n",
      "35 _aug_num :  41\n",
      "35 _category count :  43\n",
      "35 _aug_num :  41\n",
      "35 _category count :  43\n",
      "35 _aug_num :  41\n",
      "35 _category count :  43\n",
      "35 _aug_num :  41\n",
      "35 _category count :  43\n",
      "35 _aug_num :  41\n",
      "35 _category count :  43\n",
      "35 _aug_num :  41\n",
      "35 _category count :  43\n",
      "35 _aug_num :  41\n",
      "35 _category count :  43\n",
      "35 _aug_num :  41\n",
      "35 _category count :  43\n",
      "35 _aug_num :  41\n",
      "35 _category count :  43\n",
      "35 _aug_num :  41\n",
      "35 _category count :  43\n",
      "35 _aug_num :  41\n",
      "35 _category count :  43\n",
      "35 _aug_num :  41\n",
      "36 _category count :  3\n",
      "36 _aug_num :  600\n",
      "36 _category count :  3\n",
      "36 _aug_num :  600\n",
      "36 _category count :  3\n",
      "36 _aug_num :  600\n",
      "37 _category count :  15\n",
      "37 _aug_num :  120\n",
      "37 _category count :  15\n",
      "37 _aug_num :  120\n",
      "37 _category count :  15\n",
      "37 _aug_num :  120\n",
      "37 _category count :  15\n",
      "37 _aug_num :  120\n",
      "37 _category count :  15\n",
      "37 _aug_num :  120\n",
      "37 _category count :  15\n",
      "37 _aug_num :  120\n",
      "37 _category count :  15\n",
      "37 _aug_num :  120\n",
      "37 _category count :  15\n",
      "37 _aug_num :  120\n",
      "37 _category count :  15\n",
      "37 _aug_num :  120\n",
      "37 _category count :  15\n",
      "37 _aug_num :  120\n",
      "37 _category count :  15\n",
      "37 _aug_num :  120\n",
      "37 _category count :  15\n",
      "37 _aug_num :  120\n",
      "37 _category count :  15\n",
      "37 _aug_num :  120\n",
      "37 _category count :  15\n",
      "37 _aug_num :  120\n",
      "37 _category count :  15\n",
      "37 _aug_num :  120\n",
      "38 _category count :  10\n",
      "38 _aug_num :  180\n",
      "38 _category count :  10\n",
      "38 _aug_num :  180\n",
      "38 _category count :  10\n",
      "38 _aug_num :  180\n",
      "38 _category count :  10\n",
      "38 _aug_num :  180\n",
      "38 _category count :  10\n",
      "38 _aug_num :  180\n",
      "38 _category count :  10\n",
      "38 _aug_num :  180\n",
      "38 _category count :  10\n",
      "38 _aug_num :  180\n",
      "38 _category count :  10\n",
      "38 _aug_num :  180\n",
      "38 _category count :  10\n",
      "38 _aug_num :  180\n",
      "38 _category count :  10\n",
      "38 _aug_num :  180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39 _category count :  21\n",
      "39 _aug_num :  85\n",
      "39 _category count :  21\n",
      "39 _aug_num :  85\n",
      "39 _category count :  21\n",
      "39 _aug_num :  85\n",
      "39 _category count :  21\n",
      "39 _aug_num :  85\n",
      "39 _category count :  21\n",
      "39 _aug_num :  85\n",
      "39 _category count :  21\n",
      "39 _aug_num :  85\n",
      "39 _category count :  21\n",
      "39 _aug_num :  85\n",
      "39 _category count :  21\n",
      "39 _aug_num :  85\n",
      "39 _category count :  21\n",
      "39 _aug_num :  85\n",
      "39 _category count :  21\n",
      "39 _aug_num :  85\n",
      "39 _category count :  21\n",
      "39 _aug_num :  85\n",
      "39 _category count :  21\n",
      "39 _aug_num :  85\n",
      "39 _category count :  21\n",
      "39 _aug_num :  85\n",
      "39 _category count :  21\n",
      "39 _aug_num :  85\n",
      "39 _category count :  21\n",
      "39 _aug_num :  85\n",
      "39 _category count :  21\n",
      "39 _aug_num :  85\n",
      "39 _category count :  21\n",
      "39 _aug_num :  85\n",
      "39 _category count :  21\n",
      "39 _aug_num :  85\n",
      "39 _category count :  21\n",
      "39 _aug_num :  85\n",
      "39 _category count :  21\n",
      "39 _aug_num :  85\n",
      "39 _category count :  21\n",
      "39 _aug_num :  85\n",
      "4 _category count :  2\n",
      "4 _aug_num :  900\n",
      "4 _category count :  2\n",
      "4 _aug_num :  900\n",
      "40 _category count :  32\n",
      "40 _aug_num :  56\n",
      "40 _category count :  32\n",
      "40 _aug_num :  56\n",
      "40 _category count :  32\n",
      "40 _aug_num :  56\n",
      "40 _category count :  32\n",
      "40 _aug_num :  56\n",
      "40 _category count :  32\n",
      "40 _aug_num :  56\n",
      "40 _category count :  32\n",
      "40 _aug_num :  56\n",
      "40 _category count :  32\n",
      "40 _aug_num :  56\n",
      "40 _category count :  32\n",
      "40 _aug_num :  56\n",
      "40 _category count :  32\n",
      "40 _aug_num :  56\n",
      "40 _category count :  32\n",
      "40 _aug_num :  56\n",
      "40 _category count :  32\n",
      "40 _aug_num :  56\n",
      "40 _category count :  32\n",
      "40 _aug_num :  56\n",
      "40 _category count :  32\n",
      "40 _aug_num :  56\n",
      "40 _category count :  32\n",
      "40 _aug_num :  56\n",
      "40 _category count :  32\n",
      "40 _aug_num :  56\n",
      "40 _category count :  32\n",
      "40 _aug_num :  56\n",
      "40 _category count :  32\n",
      "40 _aug_num :  56\n",
      "40 _category count :  32\n",
      "40 _aug_num :  56\n",
      "40 _category count :  32\n",
      "40 _aug_num :  56\n",
      "40 _category count :  32\n",
      "40 _aug_num :  56\n",
      "40 _category count :  32\n",
      "40 _aug_num :  56\n",
      "40 _category count :  32\n",
      "40 _aug_num :  56\n",
      "40 _category count :  32\n",
      "40 _aug_num :  56\n",
      "40 _category count :  32\n",
      "40 _aug_num :  56\n",
      "40 _category count :  32\n",
      "40 _aug_num :  56\n",
      "40 _category count :  32\n",
      "40 _aug_num :  56\n",
      "40 _category count :  32\n",
      "40 _aug_num :  56\n",
      "40 _category count :  32\n",
      "40 _aug_num :  56\n",
      "40 _category count :  32\n",
      "40 _aug_num :  56\n",
      "40 _category count :  32\n",
      "40 _aug_num :  56\n",
      "40 _category count :  32\n",
      "40 _aug_num :  56\n",
      "40 _category count :  32\n",
      "40 _aug_num :  56\n",
      "41 _category count :  14\n",
      "41 _aug_num :  128\n",
      "41 _category count :  14\n",
      "41 _aug_num :  128\n",
      "41 _category count :  14\n",
      "41 _aug_num :  128\n",
      "41 _category count :  14\n",
      "41 _aug_num :  128\n",
      "41 _category count :  14\n",
      "41 _aug_num :  128\n",
      "41 _category count :  14\n",
      "41 _aug_num :  128\n",
      "41 _category count :  14\n",
      "41 _aug_num :  128\n",
      "41 _category count :  14\n",
      "41 _aug_num :  128\n",
      "41 _category count :  14\n",
      "41 _aug_num :  128\n",
      "41 _category count :  14\n",
      "41 _aug_num :  128\n",
      "41 _category count :  14\n",
      "41 _aug_num :  128\n",
      "41 _category count :  14\n",
      "41 _aug_num :  128\n",
      "41 _category count :  14\n",
      "41 _aug_num :  128\n",
      "41 _category count :  14\n",
      "41 _aug_num :  128\n",
      "42 _category count :  19\n",
      "42 _aug_num :  94\n",
      "42 _category count :  19\n",
      "42 _aug_num :  94\n",
      "42 _category count :  19\n",
      "42 _aug_num :  94\n",
      "42 _category count :  19\n",
      "42 _aug_num :  94\n",
      "42 _category count :  19\n",
      "42 _aug_num :  94\n",
      "42 _category count :  19\n",
      "42 _aug_num :  94\n",
      "42 _category count :  19\n",
      "42 _aug_num :  94\n",
      "42 _category count :  19\n",
      "42 _aug_num :  94\n",
      "42 _category count :  19\n",
      "42 _aug_num :  94\n",
      "42 _category count :  19\n",
      "42 _aug_num :  94\n",
      "42 _category count :  19\n",
      "42 _aug_num :  94\n",
      "42 _category count :  19\n",
      "42 _aug_num :  94\n",
      "42 _category count :  19\n",
      "42 _aug_num :  94\n",
      "42 _category count :  19\n",
      "42 _aug_num :  94\n",
      "42 _category count :  19\n",
      "42 _aug_num :  94\n",
      "42 _category count :  19\n",
      "42 _aug_num :  94\n",
      "42 _category count :  19\n",
      "42 _aug_num :  94\n",
      "42 _category count :  19\n",
      "42 _aug_num :  94\n",
      "42 _category count :  19\n",
      "42 _aug_num :  94\n",
      "43 _category count :  10\n",
      "43 _aug_num :  180\n",
      "43 _category count :  10\n",
      "43 _aug_num :  180\n",
      "43 _category count :  10\n",
      "43 _aug_num :  180\n",
      "43 _category count :  10\n",
      "43 _aug_num :  180\n",
      "43 _category count :  10\n",
      "43 _aug_num :  180\n",
      "43 _category count :  10\n",
      "43 _aug_num :  180\n",
      "43 _category count :  10\n",
      "43 _aug_num :  180\n",
      "43 _category count :  10\n",
      "43 _aug_num :  180\n",
      "43 _category count :  10\n",
      "43 _aug_num :  180\n",
      "43 _category count :  10\n",
      "43 _aug_num :  180\n",
      "44 _category count :  3\n",
      "44 _aug_num :  600\n",
      "44 _category count :  3\n",
      "44 _aug_num :  600\n",
      "44 _category count :  3\n",
      "44 _aug_num :  600\n",
      "45 _category count :  7\n",
      "45 _aug_num :  257\n",
      "45 _category count :  7\n",
      "45 _aug_num :  257\n",
      "45 _category count :  7\n",
      "45 _aug_num :  257\n",
      "45 _category count :  7\n",
      "45 _aug_num :  257\n",
      "45 _category count :  7\n",
      "45 _aug_num :  257\n",
      "45 _category count :  7\n",
      "45 _aug_num :  257\n",
      "45 _category count :  7\n",
      "45 _aug_num :  257\n",
      "46 _category count :  2\n",
      "46 _aug_num :  900\n",
      "46 _category count :  2\n",
      "46 _aug_num :  900\n",
      "47 _category count :  5\n",
      "47 _aug_num :  360\n",
      "47 _category count :  5\n",
      "47 _aug_num :  360\n",
      "47 _category count :  5\n",
      "47 _aug_num :  360\n",
      "47 _category count :  5\n",
      "47 _aug_num :  360\n",
      "47 _category count :  5\n",
      "47 _aug_num :  360\n",
      "48 _category count :  11\n",
      "48 _aug_num :  163\n",
      "48 _category count :  11\n",
      "48 _aug_num :  163\n",
      "48 _category count :  11\n",
      "48 _aug_num :  163\n",
      "48 _category count :  11\n",
      "48 _aug_num :  163\n",
      "48 _category count :  11\n",
      "48 _aug_num :  163\n",
      "48 _category count :  11\n",
      "48 _aug_num :  163\n",
      "48 _category count :  11\n",
      "48 _aug_num :  163\n",
      "48 _category count :  11\n",
      "48 _aug_num :  163\n",
      "48 _category count :  11\n",
      "48 _aug_num :  163\n",
      "48 _category count :  11\n",
      "48 _aug_num :  163\n",
      "48 _category count :  11\n",
      "48 _aug_num :  163\n",
      "49 _category count :  32\n",
      "49 _aug_num :  56\n",
      "49 _category count :  32\n",
      "49 _aug_num :  56\n",
      "49 _category count :  32\n",
      "49 _aug_num :  56\n",
      "49 _category count :  32\n",
      "49 _aug_num :  56\n",
      "49 _category count :  32\n",
      "49 _aug_num :  56\n",
      "49 _category count :  32\n",
      "49 _aug_num :  56\n",
      "49 _category count :  32\n",
      "49 _aug_num :  56\n",
      "49 _category count :  32\n",
      "49 _aug_num :  56\n",
      "49 _category count :  32\n",
      "49 _aug_num :  56\n",
      "49 _category count :  32\n",
      "49 _aug_num :  56\n",
      "49 _category count :  32\n",
      "49 _aug_num :  56\n",
      "49 _category count :  32\n",
      "49 _aug_num :  56\n",
      "49 _category count :  32\n",
      "49 _aug_num :  56\n",
      "49 _category count :  32\n",
      "49 _aug_num :  56\n",
      "49 _category count :  32\n",
      "49 _aug_num :  56\n",
      "49 _category count :  32\n",
      "49 _aug_num :  56\n",
      "49 _category count :  32\n",
      "49 _aug_num :  56\n",
      "49 _category count :  32\n",
      "49 _aug_num :  56\n",
      "49 _category count :  32\n",
      "49 _aug_num :  56\n",
      "49 _category count :  32\n",
      "49 _aug_num :  56\n",
      "49 _category count :  32\n",
      "49 _aug_num :  56\n",
      "49 _category count :  32\n",
      "49 _aug_num :  56\n",
      "49 _category count :  32\n",
      "49 _aug_num :  56\n",
      "49 _category count :  32\n",
      "49 _aug_num :  56\n",
      "49 _category count :  32\n",
      "49 _aug_num :  56\n",
      "49 _category count :  32\n",
      "49 _aug_num :  56\n",
      "49 _category count :  32\n",
      "49 _aug_num :  56\n",
      "49 _category count :  32\n",
      "49 _aug_num :  56\n",
      "49 _category count :  32\n",
      "49 _aug_num :  56\n",
      "49 _category count :  32\n",
      "49 _aug_num :  56\n",
      "49 _category count :  32\n",
      "49 _aug_num :  56\n",
      "49 _category count :  32\n",
      "49 _aug_num :  56\n",
      "5 _category count :  14\n",
      "5 _aug_num :  128\n",
      "5 _category count :  14\n",
      "5 _aug_num :  128\n",
      "5 _category count :  14\n",
      "5 _aug_num :  128\n",
      "5 _category count :  14\n",
      "5 _aug_num :  128\n",
      "5 _category count :  14\n",
      "5 _aug_num :  128\n",
      "5 _category count :  14\n",
      "5 _aug_num :  128\n",
      "5 _category count :  14\n",
      "5 _aug_num :  128\n",
      "5 _category count :  14\n",
      "5 _aug_num :  128\n",
      "5 _category count :  14\n",
      "5 _aug_num :  128\n",
      "5 _category count :  14\n",
      "5 _aug_num :  128\n",
      "5 _category count :  14\n",
      "5 _aug_num :  128\n",
      "5 _category count :  14\n",
      "5 _aug_num :  128\n",
      "5 _category count :  14\n",
      "5 _aug_num :  128\n",
      "5 _category count :  14\n",
      "5 _aug_num :  128\n",
      "50 _category count :  4\n",
      "50 _aug_num :  450\n",
      "50 _category count :  4\n",
      "50 _aug_num :  450\n",
      "50 _category count :  4\n",
      "50 _aug_num :  450\n",
      "50 _category count :  4\n",
      "50 _aug_num :  450\n",
      "51 _category count :  8\n",
      "51 _aug_num :  225\n",
      "51 _category count :  8\n",
      "51 _aug_num :  225\n",
      "51 _category count :  8\n",
      "51 _aug_num :  225\n",
      "51 _category count :  8\n",
      "51 _aug_num :  225\n",
      "51 _category count :  8\n",
      "51 _aug_num :  225\n",
      "51 _category count :  8\n",
      "51 _aug_num :  225\n",
      "51 _category count :  8\n",
      "51 _aug_num :  225\n",
      "51 _category count :  8\n",
      "51 _aug_num :  225\n",
      "52 _category count :  4\n",
      "52 _aug_num :  450\n",
      "52 _category count :  4\n",
      "52 _aug_num :  450\n",
      "52 _category count :  4\n",
      "52 _aug_num :  450\n",
      "52 _category count :  4\n",
      "52 _aug_num :  450\n",
      "53 _category count :  4\n",
      "53 _aug_num :  450\n",
      "53 _category count :  4\n",
      "53 _aug_num :  450\n",
      "53 _category count :  4\n",
      "53 _aug_num :  450\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53 _category count :  4\n",
      "53 _aug_num :  450\n",
      "54 _category count :  3\n",
      "54 _aug_num :  600\n",
      "54 _category count :  3\n",
      "54 _aug_num :  600\n",
      "54 _category count :  3\n",
      "54 _aug_num :  600\n",
      "55 _category count :  2\n",
      "55 _aug_num :  900\n",
      "55 _category count :  2\n",
      "55 _aug_num :  900\n",
      "56 _category count :  3\n",
      "56 _aug_num :  600\n",
      "56 _category count :  3\n",
      "56 _aug_num :  600\n",
      "56 _category count :  3\n",
      "56 _aug_num :  600\n",
      "57 _category count :  4\n",
      "57 _aug_num :  450\n",
      "57 _category count :  4\n",
      "57 _aug_num :  450\n",
      "57 _category count :  4\n",
      "57 _aug_num :  450\n",
      "57 _category count :  4\n",
      "57 _aug_num :  450\n",
      "58 _category count :  3\n",
      "58 _aug_num :  600\n",
      "58 _category count :  3\n",
      "58 _aug_num :  600\n",
      "58 _category count :  3\n",
      "58 _aug_num :  600\n",
      "59 _category count :  11\n",
      "59 _aug_num :  163\n",
      "59 _category count :  11\n",
      "59 _aug_num :  163\n",
      "59 _category count :  11\n",
      "59 _aug_num :  163\n",
      "59 _category count :  11\n",
      "59 _aug_num :  163\n",
      "59 _category count :  11\n",
      "59 _aug_num :  163\n",
      "59 _category count :  11\n",
      "59 _aug_num :  163\n",
      "59 _category count :  11\n",
      "59 _aug_num :  163\n",
      "59 _category count :  11\n",
      "59 _aug_num :  163\n",
      "59 _category count :  11\n",
      "59 _aug_num :  163\n",
      "59 _category count :  11\n",
      "59 _aug_num :  163\n",
      "59 _category count :  11\n",
      "59 _aug_num :  163\n",
      "6 _category count :  22\n",
      "6 _aug_num :  81\n",
      "6 _category count :  22\n",
      "6 _aug_num :  81\n",
      "6 _category count :  22\n",
      "6 _aug_num :  81\n",
      "6 _category count :  22\n",
      "6 _aug_num :  81\n",
      "6 _category count :  22\n",
      "6 _aug_num :  81\n",
      "6 _category count :  22\n",
      "6 _aug_num :  81\n",
      "6 _category count :  22\n",
      "6 _aug_num :  81\n",
      "6 _category count :  22\n",
      "6 _aug_num :  81\n",
      "6 _category count :  22\n",
      "6 _aug_num :  81\n",
      "6 _category count :  22\n",
      "6 _aug_num :  81\n",
      "6 _category count :  22\n",
      "6 _aug_num :  81\n",
      "6 _category count :  22\n",
      "6 _aug_num :  81\n",
      "6 _category count :  22\n",
      "6 _aug_num :  81\n",
      "6 _category count :  22\n",
      "6 _aug_num :  81\n",
      "6 _category count :  22\n",
      "6 _aug_num :  81\n",
      "6 _category count :  22\n",
      "6 _aug_num :  81\n",
      "6 _category count :  22\n",
      "6 _aug_num :  81\n",
      "6 _category count :  22\n",
      "6 _aug_num :  81\n",
      "6 _category count :  22\n",
      "6 _aug_num :  81\n",
      "6 _category count :  22\n",
      "6 _aug_num :  81\n",
      "6 _category count :  22\n",
      "6 _aug_num :  81\n",
      "6 _category count :  22\n",
      "6 _aug_num :  81\n",
      "60 _category count :  37\n",
      "60 _aug_num :  48\n",
      "60 _category count :  37\n",
      "60 _aug_num :  48\n",
      "60 _category count :  37\n",
      "60 _aug_num :  48\n",
      "60 _category count :  37\n",
      "60 _aug_num :  48\n",
      "60 _category count :  37\n",
      "60 _aug_num :  48\n",
      "60 _category count :  37\n",
      "60 _aug_num :  48\n",
      "60 _category count :  37\n",
      "60 _aug_num :  48\n",
      "60 _category count :  37\n",
      "60 _aug_num :  48\n",
      "60 _category count :  37\n",
      "60 _aug_num :  48\n",
      "60 _category count :  37\n",
      "60 _aug_num :  48\n",
      "60 _category count :  37\n",
      "60 _aug_num :  48\n",
      "60 _category count :  37\n",
      "60 _aug_num :  48\n",
      "60 _category count :  37\n",
      "60 _aug_num :  48\n",
      "60 _category count :  37\n",
      "60 _aug_num :  48\n",
      "60 _category count :  37\n",
      "60 _aug_num :  48\n",
      "60 _category count :  37\n",
      "60 _aug_num :  48\n",
      "60 _category count :  37\n",
      "60 _aug_num :  48\n",
      "60 _category count :  37\n",
      "60 _aug_num :  48\n",
      "60 _category count :  37\n",
      "60 _aug_num :  48\n",
      "60 _category count :  37\n",
      "60 _aug_num :  48\n",
      "60 _category count :  37\n",
      "60 _aug_num :  48\n",
      "60 _category count :  37\n",
      "60 _aug_num :  48\n",
      "60 _category count :  37\n",
      "60 _aug_num :  48\n",
      "60 _category count :  37\n",
      "60 _aug_num :  48\n",
      "60 _category count :  37\n",
      "60 _aug_num :  48\n",
      "60 _category count :  37\n",
      "60 _aug_num :  48\n",
      "60 _category count :  37\n",
      "60 _aug_num :  48\n",
      "60 _category count :  37\n",
      "60 _aug_num :  48\n",
      "60 _category count :  37\n",
      "60 _aug_num :  48\n",
      "60 _category count :  37\n",
      "60 _aug_num :  48\n",
      "60 _category count :  37\n",
      "60 _aug_num :  48\n",
      "60 _category count :  37\n",
      "60 _aug_num :  48\n",
      "60 _category count :  37\n",
      "60 _aug_num :  48\n",
      "60 _category count :  37\n",
      "60 _aug_num :  48\n",
      "60 _category count :  37\n",
      "60 _aug_num :  48\n",
      "60 _category count :  37\n",
      "60 _aug_num :  48\n",
      "60 _category count :  37\n",
      "60 _aug_num :  48\n",
      "61 _category count :  11\n",
      "61 _aug_num :  163\n",
      "61 _category count :  11\n",
      "61 _aug_num :  163\n",
      "61 _category count :  11\n",
      "61 _aug_num :  163\n",
      "61 _category count :  11\n",
      "61 _aug_num :  163\n",
      "61 _category count :  11\n",
      "61 _aug_num :  163\n",
      "61 _category count :  11\n",
      "61 _aug_num :  163\n",
      "61 _category count :  11\n",
      "61 _aug_num :  163\n",
      "61 _category count :  11\n",
      "61 _aug_num :  163\n",
      "61 _category count :  11\n",
      "61 _aug_num :  163\n",
      "61 _category count :  11\n",
      "61 _aug_num :  163\n",
      "61 _category count :  11\n",
      "61 _aug_num :  163\n",
      "62 _category count :  52\n",
      "62 _aug_num :  34\n",
      "62 _category count :  52\n",
      "62 _aug_num :  34\n",
      "62 _category count :  52\n",
      "62 _aug_num :  34\n",
      "62 _category count :  52\n",
      "62 _aug_num :  34\n",
      "62 _category count :  52\n",
      "62 _aug_num :  34\n",
      "62 _category count :  52\n",
      "62 _aug_num :  34\n",
      "62 _category count :  52\n",
      "62 _aug_num :  34\n",
      "62 _category count :  52\n",
      "62 _aug_num :  34\n",
      "62 _category count :  52\n",
      "62 _aug_num :  34\n",
      "62 _category count :  52\n",
      "62 _aug_num :  34\n",
      "62 _category count :  52\n",
      "62 _aug_num :  34\n",
      "62 _category count :  52\n",
      "62 _aug_num :  34\n",
      "62 _category count :  52\n",
      "62 _aug_num :  34\n",
      "62 _category count :  52\n",
      "62 _aug_num :  34\n",
      "62 _category count :  52\n",
      "62 _aug_num :  34\n",
      "62 _category count :  52\n",
      "62 _aug_num :  34\n",
      "62 _category count :  52\n",
      "62 _aug_num :  34\n",
      "62 _category count :  52\n",
      "62 _aug_num :  34\n",
      "62 _category count :  52\n",
      "62 _aug_num :  34\n",
      "62 _category count :  52\n",
      "62 _aug_num :  34\n",
      "62 _category count :  52\n",
      "62 _aug_num :  34\n",
      "62 _category count :  52\n",
      "62 _aug_num :  34\n",
      "62 _category count :  52\n",
      "62 _aug_num :  34\n",
      "62 _category count :  52\n",
      "62 _aug_num :  34\n",
      "62 _category count :  52\n",
      "62 _aug_num :  34\n",
      "62 _category count :  52\n",
      "62 _aug_num :  34\n",
      "62 _category count :  52\n",
      "62 _aug_num :  34\n",
      "62 _category count :  52\n",
      "62 _aug_num :  34\n",
      "62 _category count :  52\n",
      "62 _aug_num :  34\n",
      "62 _category count :  52\n",
      "62 _aug_num :  34\n",
      "62 _category count :  52\n",
      "62 _aug_num :  34\n",
      "62 _category count :  52\n",
      "62 _aug_num :  34\n",
      "62 _category count :  52\n",
      "62 _aug_num :  34\n",
      "62 _category count :  52\n",
      "62 _aug_num :  34\n",
      "62 _category count :  52\n",
      "62 _aug_num :  34\n",
      "62 _category count :  52\n",
      "62 _aug_num :  34\n",
      "62 _category count :  52\n",
      "62 _aug_num :  34\n",
      "62 _category count :  52\n",
      "62 _aug_num :  34\n",
      "62 _category count :  52\n",
      "62 _aug_num :  34\n",
      "62 _category count :  52\n",
      "62 _aug_num :  34\n",
      "62 _category count :  52\n",
      "62 _aug_num :  34\n",
      "62 _category count :  52\n",
      "62 _aug_num :  34\n",
      "62 _category count :  52\n",
      "62 _aug_num :  34\n",
      "62 _category count :  52\n",
      "62 _aug_num :  34\n",
      "62 _category count :  52\n",
      "62 _aug_num :  34\n",
      "62 _category count :  52\n",
      "62 _aug_num :  34\n",
      "62 _category count :  52\n",
      "62 _aug_num :  34\n",
      "62 _category count :  52\n",
      "62 _aug_num :  34\n",
      "62 _category count :  52\n",
      "62 _aug_num :  34\n",
      "62 _category count :  52\n",
      "62 _aug_num :  34\n",
      "62 _category count :  52\n",
      "62 _aug_num :  34\n",
      "62 _category count :  52\n",
      "62 _aug_num :  34\n",
      "63 _category count :  3\n",
      "63 _aug_num :  600\n",
      "63 _category count :  3\n",
      "63 _aug_num :  600\n",
      "63 _category count :  3\n",
      "63 _aug_num :  600\n",
      "64 _category count :  10\n",
      "64 _aug_num :  180\n",
      "64 _category count :  10\n",
      "64 _aug_num :  180\n",
      "64 _category count :  10\n",
      "64 _aug_num :  180\n",
      "64 _category count :  10\n",
      "64 _aug_num :  180\n",
      "64 _category count :  10\n",
      "64 _aug_num :  180\n",
      "64 _category count :  10\n",
      "64 _aug_num :  180\n",
      "64 _category count :  10\n",
      "64 _aug_num :  180\n",
      "64 _category count :  10\n",
      "64 _aug_num :  180\n",
      "64 _category count :  10\n",
      "64 _aug_num :  180\n",
      "64 _category count :  10\n",
      "64 _aug_num :  180\n",
      "65 _category count :  2\n",
      "65 _aug_num :  900\n",
      "65 _category count :  2\n",
      "65 _aug_num :  900\n",
      "66 _category count :  3\n",
      "66 _aug_num :  600\n",
      "66 _category count :  3\n",
      "66 _aug_num :  600\n",
      "66 _category count :  3\n",
      "66 _aug_num :  600\n",
      "67 _category count :  2\n",
      "67 _aug_num :  900\n",
      "67 _category count :  2\n",
      "67 _aug_num :  900\n",
      "68 _category count :  2\n",
      "68 _aug_num :  900\n",
      "68 _category count :  2\n",
      "68 _aug_num :  900\n",
      "69 _category count :  3\n",
      "69 _aug_num :  600\n",
      "69 _category count :  3\n",
      "69 _aug_num :  600\n",
      "69 _category count :  3\n",
      "69 _aug_num :  600\n",
      "7 _category count :  5\n",
      "7 _aug_num :  360\n",
      "7 _category count :  5\n",
      "7 _aug_num :  360\n",
      "7 _category count :  5\n",
      "7 _aug_num :  360\n",
      "7 _category count :  5\n",
      "7 _aug_num :  360\n",
      "7 _category count :  5\n",
      "7 _aug_num :  360\n",
      "70 _category count :  2\n",
      "70 _aug_num :  900\n",
      "70 _category count :  2\n",
      "70 _aug_num :  900\n",
      "71 _category count :  5\n",
      "71 _aug_num :  360\n",
      "71 _category count :  5\n",
      "71 _aug_num :  360\n",
      "71 _category count :  5\n",
      "71 _aug_num :  360\n",
      "71 _category count :  5\n",
      "71 _aug_num :  360\n",
      "71 _category count :  5\n",
      "71 _aug_num :  360\n",
      "72 _category count :  4\n",
      "72 _aug_num :  450\n",
      "72 _category count :  4\n",
      "72 _aug_num :  450\n",
      "72 _category count :  4\n",
      "72 _aug_num :  450\n",
      "72 _category count :  4\n",
      "72 _aug_num :  450\n",
      "73 _category count :  6\n",
      "73 _aug_num :  300\n",
      "73 _category count :  6\n",
      "73 _aug_num :  300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73 _category count :  6\n",
      "73 _aug_num :  300\n",
      "73 _category count :  6\n",
      "73 _aug_num :  300\n",
      "73 _category count :  6\n",
      "73 _aug_num :  300\n",
      "73 _category count :  6\n",
      "73 _aug_num :  300\n",
      "74 _category count :  2\n",
      "74 _aug_num :  900\n",
      "74 _category count :  2\n",
      "74 _aug_num :  900\n",
      "75 _category count :  2\n",
      "75 _aug_num :  900\n",
      "75 _category count :  2\n",
      "75 _aug_num :  900\n",
      "76 _category count :  3\n",
      "76 _aug_num :  600\n",
      "76 _category count :  3\n",
      "76 _aug_num :  600\n",
      "76 _category count :  3\n",
      "76 _aug_num :  600\n",
      "77 _category count :  2\n",
      "77 _aug_num :  900\n",
      "77 _category count :  2\n",
      "77 _aug_num :  900\n",
      "78 _category count :  2\n",
      "78 _aug_num :  900\n",
      "78 _category count :  2\n",
      "78 _aug_num :  900\n",
      "79 _category count :  3\n",
      "79 _aug_num :  600\n",
      "79 _category count :  3\n",
      "79 _aug_num :  600\n",
      "79 _category count :  3\n",
      "79 _aug_num :  600\n",
      "8 _category count :  4\n",
      "8 _aug_num :  450\n",
      "8 _category count :  4\n",
      "8 _aug_num :  450\n",
      "8 _category count :  4\n",
      "8 _aug_num :  450\n",
      "8 _category count :  4\n",
      "8 _aug_num :  450\n",
      "80 _category count :  2\n",
      "80 _aug_num :  900\n",
      "80 _category count :  2\n",
      "80 _aug_num :  900\n",
      "81 _category count :  2\n",
      "81 _aug_num :  900\n",
      "81 _category count :  2\n",
      "81 _aug_num :  900\n",
      "82 _category count :  3\n",
      "82 _aug_num :  600\n",
      "82 _category count :  3\n",
      "82 _aug_num :  600\n",
      "82 _category count :  3\n",
      "82 _aug_num :  600\n",
      "83 _category count :  2\n",
      "83 _aug_num :  900\n",
      "83 _category count :  2\n",
      "83 _aug_num :  900\n",
      "84 _category count :  2\n",
      "84 _aug_num :  900\n",
      "84 _category count :  2\n",
      "84 _aug_num :  900\n",
      "85 _category count :  2\n",
      "85 _aug_num :  900\n",
      "85 _category count :  2\n",
      "85 _aug_num :  900\n",
      "86 _category count :  2\n",
      "86 _aug_num :  900\n",
      "86 _category count :  2\n",
      "86 _aug_num :  900\n",
      "87 _category count :  2\n",
      "87 _aug_num :  900\n",
      "87 _category count :  2\n",
      "87 _aug_num :  900\n",
      "88 _category count :  2\n",
      "88 _aug_num :  900\n",
      "88 _category count :  2\n",
      "88 _aug_num :  900\n",
      "89 _category count :  2\n",
      "89 _aug_num :  900\n",
      "89 _category count :  2\n",
      "89 _aug_num :  900\n",
      "9 _category count :  3\n",
      "9 _aug_num :  600\n",
      "9 _category count :  3\n",
      "9 _aug_num :  600\n",
      "9 _category count :  3\n",
      "9 _aug_num :  600\n",
      "90 _category count :  2\n",
      "90 _aug_num :  900\n",
      "90 _category count :  2\n",
      "90 _aug_num :  900\n"
     ]
    }
   ],
   "source": [
    "''' 전처리 함수 메뉴\n",
    "1. original : 원본 이미지\n",
    "2. threshold : Adaptive만 적용\n",
    "3. morphology : morph gradient만 적용\n",
    "4. threshold_sole : 이미지 대비 향상 -> Adaptive\n",
    "5. morph_threshold : morph gradient -> Adaptive \n",
    "6. morph_threshold_sole : 이미지 대비 향상 morph gradient -> adaptive threshold \n",
    "'''\n",
    "\n",
    "\n",
    "##ImageDataGenerator에 원하는 옵션들을 추가해주면 옵션들 적용하면서 랜덤하게 생성해줍니다.\n",
    "with tf.device('/device:GPU:0'):\n",
    "    datagen = ImageDataGenerator(\n",
    "            rotation_range = 90,\n",
    "            width_shift_range = 0.2,\n",
    "            height_shift_range = 0.2,\n",
    "            brightness_range = [0.05 , 2.0],\n",
    "            vertical_flip = True,\n",
    "            horizontal_flip = True,\n",
    "            fill_mode= 'nearest')\n",
    "    # 전처리 함수 자기 파트 # 빼고 진행하기\n",
    "    #function = original # 선민\n",
    "    #function = threshold # 세웅\n",
    "    #function = threshold_sole # 예림\n",
    "    #function = morph_threshold # 솔\n",
    "    function = morph_threshold_sole # 서현\n",
    "\n",
    "    for img_path in my_img_pathes:\n",
    "\n",
    "        ''' category별 개수 구하기 '''\n",
    "        img_name, category_count, category_num = count_category(img_path, category_count_dict)\n",
    "\n",
    "        ''' 전처리 '''\n",
    "\n",
    "        x = preprocess(img_path, function)\n",
    "\n",
    "        ''' Augment & Save '''\n",
    "\n",
    "        # augmentation 개수\n",
    "        img_num = 1800 # 1680 : 210의 배수로 해줘야 각 폴더에 들어가는 이미지 수가 최대한 비슷해짐\n",
    "        aug_num = int(img_num/category_count)\n",
    "        print(category_num, '_category count : ', category_count)\n",
    "        print(category_num, '_aug_num : ', aug_num)\n",
    "\n",
    "        # if img_num%category_count != 0: # 여기서 print의 결과로 나오는 이미지들은 10000의 약수가 아니므로, augmentation한 결과가 정확히 10000장이 되지 못함. 해당 카테고리에서는 수동으로 이미지 복붙해서 10000장 맞춰주세요.\n",
    "        #    print(category_num)\n",
    "\n",
    "\n",
    "        # 아래 폴더 이름은 \"C:/Users/seohyeonpark/프로젝트\" 부분만 원하는 경로로 바꿔주세요. \n",
    "        folder_path = \"C:/Users/seohyeonpark/프로젝트/Data Augmentation2\" + \"/\" + str(category_num) # folder_path는 자기가 저장할 경로에 맞게 수정해주어야 함. str(category)는 건들지 말고 앞부분만 수정.\n",
    "        if not(os.path.isdir(folder_path)):\n",
    "            os.makedirs(folder_path)\n",
    "        j=0\n",
    "        for batch in datagen.flow(x,\n",
    "                                  batch_size=1,\n",
    "                                  save_to_dir=folder_path,\n",
    "                                  save_prefix=category_num,\n",
    "                                  save_format=\"jpeg\"):\n",
    "            j+=1\n",
    "            if j > aug_num:\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 각 카테고리 별로 augmentation 이미지 15개 씩 augmented_validation 폴더에 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_num = []\n",
    "for i in category_nums:\n",
    "    if i not in category_num:\n",
    "        category_num.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "for i in category_num:\n",
    "    ith_images = glob.glob(\"C:/Users/seohyeonpark/프로젝트/Data Augmentation2\" + \"/\" + str(i) + \"/*.jpeg\")\n",
    "    remove_images_pathes = random.sample(ith_images, len(ith_images) - 1500)\n",
    "    for path in remove_images_pathes:\n",
    "        os.remove(path)\n",
    "                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "for category in category_num:\n",
    "    # 해당 category 폴더에서 무작위로 선택된 15개의 이미지 경로를 저장 (경로 지정해줘야 함)\n",
    "    folder_path = \"C:/Users/seohyeonpark/프로젝트/Data Augmentation2\" + \"/\" + str(category)\n",
    "    \n",
    "    all_images_pathes = glob.glob(folder_path+\"/*.jpeg\")\n",
    "    \n",
    "    # 아래 부분은 위의 my_image_pathes와 같이 주소가 정상적으로 안 불러져 왔을 경우에만 실행\n",
    "    i = 0\n",
    "    for path in all_images_pathes:\n",
    "        path = path.replace('\\\\','/')\n",
    "        all_images_pathes[i] = path\n",
    "        i += 1\n",
    "    \n",
    "    selected_images_pathes = random.sample(all_images_pathes, 111)\n",
    "    \n",
    "    # 이동할 폴더 생성(경로 지정해줘야 함)\n",
    "    to_images_pathes = \"C:/Users/seohyeonpark/프로젝트/augmented_validation2\" + \"/\" + str(category)\n",
    "    os.makedirs(to_images_pathes)\n",
    "    \n",
    "    for selected_image_path in selected_images_pathes:\n",
    "        file_name = selected_image_path.split('/')[-1]\n",
    "        from_image_path = folder_path + \"/\" + file_name\n",
    "        shutil.move(from_image_path, to_images_pathes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 원본 이미지로 validation set 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(my_img_pathes)):\n",
    "    from_image_path = my_img_pathes[i]\n",
    "    file_name = my_img_pathes[i].split('/')[-1]\n",
    "    category_num = file_name.split('.')[0]\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        category_num = int(category_num) # (i)번 째 안되어 있으면 바로 정수형으로 바꿔잇!\n",
    "    except:\n",
    "        if \"(\" in category_num: # (i)번째 표시되어있으면 날리고 앞에 카테고리만 저장\n",
    "            category_num = int(category_num.split(\"(\")[0])\n",
    "        elif \"-\" in category_num: # - i 로 표시한 사람것도 날리고 앞에 카테고리만 저장\n",
    "            category_num = int(category_num.split('-')[0])\n",
    "    \n",
    "    to_images_pathes = \"C:/Users/seohyeonpark/프로젝트/original_validation2\" + \"/\" + str(category_num)\n",
    "    if not(os.path.isdir(to_images_pathes)):\n",
    "        os.makedirs(to_images_pathes)\n",
    "    shutil.copy(from_image_path, to_images_pathes + \"/\" + file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 이후에는 세웅이 모델 학습 붙이기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "##alphanumeric order\n",
    "def sort(lst): \n",
    "    lst = [str(i) for i in lst] \n",
    "    lst.sort() \n",
    "    lst = [int(i) if i.isdigit() else i for i in lst ] \n",
    "    return lst \n",
    "\n",
    "## training data에 label 붙여주기\n",
    "num_list = []\n",
    "for i in range(91):\n",
    "    num_list.append(i)\n",
    "\n",
    "## wheel_imgs_num dictionary : {카테고리 번호 : 카테고리 속하는 이미지 갯수}\n",
    "wheel_imgs_num = {}\n",
    "for idx in num_list:\n",
    "    wheel_img_path = glob.glob('C:/Users/seohyeonpark/프로젝트/Data Augmentation2/%s/*.jpeg' % idx) ## %s 부분은 '카테고리 번호명인 폴더'를 의미하니, 참고하여 경로를 설정해주시면 됩니다.  \n",
    "    wheel_imgs_num[idx] = len(wheel_img_path)\n",
    "    \n",
    "## 빈 array를 만들고, alphanumeric order로 레이블 만들기 : wheel_imgs_num.keys()를 sort함수 적용하면 alphanumeric order로 순회합니다.\n",
    "## 빈 array에 np.concatenate로 numpy 배열 붙여나가는 방식으로 labeling 했습니다.\n",
    "label_trained = np.array([], dtype ='int32')\n",
    "for idx in sort(wheel_imgs_num.keys()):\n",
    "    x = np.array([idx]*wheel_imgs_num[idx], dtype ='int32') ## [카테고리 번호]를 카테고리 속하는 이미지 갯수만큼 배열 만들기\n",
    "    label_trained = np.concatenate((label_trained,x)) ## 배열 붙이기\n",
    "    \n",
    "del wheel_imgs_num\n",
    "del wheel_img_path\n",
    "del x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: image_classifiers==0.2.2 in c:\\users\\seohyeonpark\\anaconda3\\envs\\wheel-similarity\\lib\\site-packages (0.2.2)\n",
      "Requirement already satisfied: keras>=2.1.0 in c:\\users\\seohyeonpark\\anaconda3\\envs\\wheel-similarity\\lib\\site-packages (from image_classifiers==0.2.2) (2.3.1)\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\users\\seohyeonpark\\anaconda3\\envs\\wheel-similarity\\lib\\site-packages (from keras>=2.1.0->image_classifiers==0.2.2) (1.18.1)\n",
      "Requirement already satisfied: scipy>=0.14 in c:\\users\\seohyeonpark\\anaconda3\\envs\\wheel-similarity\\lib\\site-packages (from keras>=2.1.0->image_classifiers==0.2.2) (1.4.1)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\seohyeonpark\\anaconda3\\envs\\wheel-similarity\\lib\\site-packages (from keras>=2.1.0->image_classifiers==0.2.2) (1.15.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\seohyeonpark\\anaconda3\\envs\\wheel-similarity\\lib\\site-packages (from keras>=2.1.0->image_classifiers==0.2.2) (5.3.1)\n",
      "Requirement already satisfied: h5py in c:\\users\\seohyeonpark\\anaconda3\\envs\\wheel-similarity\\lib\\site-packages (from keras>=2.1.0->image_classifiers==0.2.2) (2.8.0)\n",
      "Requirement already satisfied: keras_applications>=1.0.6 in c:\\users\\seohyeonpark\\anaconda3\\envs\\wheel-similarity\\lib\\site-packages (from keras>=2.1.0->image_classifiers==0.2.2) (1.0.8)\n",
      "Requirement already satisfied: keras_preprocessing>=1.0.5 in c:\\users\\seohyeonpark\\anaconda3\\envs\\wheel-similarity\\lib\\site-packages (from keras>=2.1.0->image_classifiers==0.2.2) (1.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install image_classifiers==0.2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from classification_models.resnet import ResNet50, preprocess_input\n",
    "from skimage.transform import resize\n",
    "from PIL import Image\n",
    "model = ResNet50(input_shape=(224,224,3), weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def result(img,model):\n",
    "    x = resize(img,(224,224))*255\n",
    "    x = preprocess_input(x)\n",
    "    x = np.expand_dims(x,0)\n",
    "    y = model.predict(x)\n",
    "    y = np.mean(y, axis=(1,2))\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/seohyeonpark/프로젝트/Data Augmentation2/0is done.\n",
      "C:/Users/seohyeonpark/프로젝트/Data Augmentation2/1is done.\n",
      "C:/Users/seohyeonpark/프로젝트/Data Augmentation2/10is done.\n",
      "C:/Users/seohyeonpark/프로젝트/Data Augmentation2/11is done.\n",
      "C:/Users/seohyeonpark/프로젝트/Data Augmentation2/12is done.\n",
      "C:/Users/seohyeonpark/프로젝트/Data Augmentation2/13is done.\n",
      "C:/Users/seohyeonpark/프로젝트/Data Augmentation2/14is done.\n",
      "C:/Users/seohyeonpark/프로젝트/Data Augmentation2/15is done.\n",
      "C:/Users/seohyeonpark/프로젝트/Data Augmentation2/16is done.\n",
      "C:/Users/seohyeonpark/프로젝트/Data Augmentation2/17is done.\n",
      "C:/Users/seohyeonpark/프로젝트/Data Augmentation2/18is done.\n",
      "C:/Users/seohyeonpark/프로젝트/Data Augmentation2/19is done.\n",
      "C:/Users/seohyeonpark/프로젝트/Data Augmentation2/2is done.\n",
      "C:/Users/seohyeonpark/프로젝트/Data Augmentation2/20is done.\n",
      "C:/Users/seohyeonpark/프로젝트/Data Augmentation2/21is done.\n",
      "C:/Users/seohyeonpark/프로젝트/Data Augmentation2/22is done.\n",
      "C:/Users/seohyeonpark/프로젝트/Data Augmentation2/23is done.\n",
      "C:/Users/seohyeonpark/프로젝트/Data Augmentation2/24is done.\n",
      "C:/Users/seohyeonpark/프로젝트/Data Augmentation2/25is done.\n",
      "C:/Users/seohyeonpark/프로젝트/Data Augmentation2/26is done.\n",
      "C:/Users/seohyeonpark/프로젝트/Data Augmentation2/27is done.\n",
      "C:/Users/seohyeonpark/프로젝트/Data Augmentation2/28is done.\n",
      "C:/Users/seohyeonpark/프로젝트/Data Augmentation2/29is done.\n",
      "C:/Users/seohyeonpark/프로젝트/Data Augmentation2/3is done.\n",
      "C:/Users/seohyeonpark/프로젝트/Data Augmentation2/30is done.\n",
      "C:/Users/seohyeonpark/프로젝트/Data Augmentation2/31is done.\n",
      "C:/Users/seohyeonpark/프로젝트/Data Augmentation2/32is done.\n",
      "C:/Users/seohyeonpark/프로젝트/Data Augmentation2/33is done.\n",
      "C:/Users/seohyeonpark/프로젝트/Data Augmentation2/34is done.\n",
      "C:/Users/seohyeonpark/프로젝트/Data Augmentation2/35is done.\n",
      "C:/Users/seohyeonpark/프로젝트/Data Augmentation2/36is done.\n",
      "C:/Users/seohyeonpark/프로젝트/Data Augmentation2/37is done.\n",
      "C:/Users/seohyeonpark/프로젝트/Data Augmentation2/38is done.\n",
      "C:/Users/seohyeonpark/프로젝트/Data Augmentation2/39is done.\n",
      "C:/Users/seohyeonpark/프로젝트/Data Augmentation2/4is done.\n",
      "C:/Users/seohyeonpark/프로젝트/Data Augmentation2/40is done.\n",
      "C:/Users/seohyeonpark/프로젝트/Data Augmentation2/41is done.\n",
      "C:/Users/seohyeonpark/프로젝트/Data Augmentation2/42is done.\n",
      "C:/Users/seohyeonpark/프로젝트/Data Augmentation2/43is done.\n",
      "C:/Users/seohyeonpark/프로젝트/Data Augmentation2/44is done.\n",
      "C:/Users/seohyeonpark/프로젝트/Data Augmentation2/45is done.\n",
      "C:/Users/seohyeonpark/프로젝트/Data Augmentation2/46is done.\n",
      "C:/Users/seohyeonpark/프로젝트/Data Augmentation2/47is done.\n",
      "C:/Users/seohyeonpark/프로젝트/Data Augmentation2/48is done.\n",
      "C:/Users/seohyeonpark/프로젝트/Data Augmentation2/49is done.\n",
      "C:/Users/seohyeonpark/프로젝트/Data Augmentation2/5is done.\n",
      "C:/Users/seohyeonpark/프로젝트/Data Augmentation2/50is done.\n",
      "C:/Users/seohyeonpark/프로젝트/Data Augmentation2/51is done.\n",
      "C:/Users/seohyeonpark/프로젝트/Data Augmentation2/52is done.\n",
      "C:/Users/seohyeonpark/프로젝트/Data Augmentation2/53is done.\n",
      "C:/Users/seohyeonpark/프로젝트/Data Augmentation2/54is done.\n",
      "C:/Users/seohyeonpark/프로젝트/Data Augmentation2/55is done.\n",
      "C:/Users/seohyeonpark/프로젝트/Data Augmentation2/56is done.\n",
      "C:/Users/seohyeonpark/프로젝트/Data Augmentation2/57is done.\n",
      "C:/Users/seohyeonpark/프로젝트/Data Augmentation2/58is done.\n",
      "C:/Users/seohyeonpark/프로젝트/Data Augmentation2/59is done.\n",
      "C:/Users/seohyeonpark/프로젝트/Data Augmentation2/6is done.\n",
      "C:/Users/seohyeonpark/프로젝트/Data Augmentation2/60is done.\n",
      "C:/Users/seohyeonpark/프로젝트/Data Augmentation2/61is done.\n",
      "C:/Users/seohyeonpark/프로젝트/Data Augmentation2/62is done.\n",
      "C:/Users/seohyeonpark/프로젝트/Data Augmentation2/63is done.\n",
      "C:/Users/seohyeonpark/프로젝트/Data Augmentation2/64is done.\n",
      "C:/Users/seohyeonpark/프로젝트/Data Augmentation2/65is done.\n",
      "C:/Users/seohyeonpark/프로젝트/Data Augmentation2/66is done.\n",
      "C:/Users/seohyeonpark/프로젝트/Data Augmentation2/67is done.\n",
      "C:/Users/seohyeonpark/프로젝트/Data Augmentation2/68is done.\n",
      "C:/Users/seohyeonpark/프로젝트/Data Augmentation2/69is done.\n",
      "C:/Users/seohyeonpark/프로젝트/Data Augmentation2/7is done.\n",
      "C:/Users/seohyeonpark/프로젝트/Data Augmentation2/70is done.\n",
      "C:/Users/seohyeonpark/프로젝트/Data Augmentation2/71is done.\n",
      "C:/Users/seohyeonpark/프로젝트/Data Augmentation2/72is done.\n",
      "C:/Users/seohyeonpark/프로젝트/Data Augmentation2/73is done.\n",
      "C:/Users/seohyeonpark/프로젝트/Data Augmentation2/74is done.\n",
      "C:/Users/seohyeonpark/프로젝트/Data Augmentation2/75is done.\n",
      "C:/Users/seohyeonpark/프로젝트/Data Augmentation2/76is done.\n",
      "C:/Users/seohyeonpark/프로젝트/Data Augmentation2/77is done.\n",
      "C:/Users/seohyeonpark/프로젝트/Data Augmentation2/78is done.\n",
      "C:/Users/seohyeonpark/프로젝트/Data Augmentation2/79is done.\n",
      "C:/Users/seohyeonpark/프로젝트/Data Augmentation2/8is done.\n",
      "C:/Users/seohyeonpark/프로젝트/Data Augmentation2/80is done.\n",
      "C:/Users/seohyeonpark/프로젝트/Data Augmentation2/81is done.\n",
      "C:/Users/seohyeonpark/프로젝트/Data Augmentation2/82is done.\n",
      "C:/Users/seohyeonpark/프로젝트/Data Augmentation2/83is done.\n",
      "C:/Users/seohyeonpark/프로젝트/Data Augmentation2/84is done.\n",
      "C:/Users/seohyeonpark/프로젝트/Data Augmentation2/85is done.\n",
      "C:/Users/seohyeonpark/프로젝트/Data Augmentation2/86is done.\n",
      "C:/Users/seohyeonpark/프로젝트/Data Augmentation2/87is done.\n",
      "C:/Users/seohyeonpark/프로젝트/Data Augmentation2/88is done.\n",
      "C:/Users/seohyeonpark/프로젝트/Data Augmentation2/89is done.\n",
      "C:/Users/seohyeonpark/프로젝트/Data Augmentation2/9is done.\n",
      "C:/Users/seohyeonpark/프로젝트/Data Augmentation2/90is done.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:/Users/seohyeonpark/프로젝트/feature vector/bottleneck_features_train.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-87a85185b373>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfolder_path\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"is done.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m     \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'C:/Users/seohyeonpark/프로젝트/feature vector/bottleneck_features_train.npy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_img_array\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36msave\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\wheel-similarity\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(file, arr, allow_pickle, fix_imports)\u001b[0m\n\u001b[0;32m    539\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'.npy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m             \u001b[0mfile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfile\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'.npy'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 541\u001b[1;33m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"wb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    542\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    543\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:/Users/seohyeonpark/프로젝트/feature vector/bottleneck_features_train.npy'"
     ]
    }
   ],
   "source": [
    "with tf.device('/device:GPU:0'):\n",
    "    train_img_array = np.zeros((len(label_trained),2048))\n",
    "    pathes = glob.glob(\"C:/Users/seohyeonpark/프로젝트/Data Augmentation2/*\")\n",
    "    # 아래 부분은 위의 my_image_pathes와 같이 주소가 정상적으로 안 불러져 왔을 경우에만 실행\n",
    "    idx = 0\n",
    "    for path in pathes:\n",
    "        path = path.replace('\\\\','/')\n",
    "        pathes[idx] = path\n",
    "        idx += 1\n",
    "    sorted_pathes = sort(pathes)\n",
    "    del pathes\n",
    "\n",
    "    for folder_path in sorted_pathes:\n",
    "        img_pathes = glob.glob(folder_path+\"/*.jpeg\")\n",
    "        #j = 0\n",
    "        #for path in img_pathes:\n",
    "        #    path = path.replace('\\\\','/')\n",
    "        #    img_pathes[i] = path\n",
    "        #    j += 1\n",
    "\n",
    "        for i in range(len(img_pathes)):\n",
    "            img = Image.open(img_pathes[i])\n",
    "            img_numpy = np.array(img)\n",
    "            img_vector = result(img_numpy,model)\n",
    "            train_img_array[i] = img_vector\n",
    "            del img\n",
    "            del img_numpy\n",
    "            del img_vector\n",
    "        print(folder_path+\"is done.\")\n",
    "\n",
    "    np.save('C:/Users/seohyeonpark/프로젝트/feature vector/bottleneck_features_train.npy', train_img_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('C:/Users/seohyeonpark/프로젝트/feature_vector/bottleneck_features_train.npy', train_img_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "with tf.device('/device:GPU:0'):\n",
    "    num_list = []\n",
    "    for i in range(91):\n",
    "        num_list.append(i)\n",
    "\n",
    "    ## wheel_imgs_num dictionary : {카테고리 번호 : 카테고리 속하는 이미지 갯수}\n",
    "    wheel_imgs_num = {}\n",
    "\n",
    "    for idx in num_list:\n",
    "        wheel_img_path = glob.glob('C:/Users/seohyeonpark/프로젝트/augmented_validation2/%s/*.jpeg' % idx) ## %s 부분은 '카테고리 번호명인 폴더'를 의미하니, 참고하여 경로를 설정해주시면 됩니다.  \n",
    "        wheel_imgs_num[idx] = len(wheel_img_path)\n",
    "\n",
    "    ## 빈 array를 만들고, alphanumeric order로 레이블 만들기 : wheel_imgs_num.keys()를 sort함수 적용하면 alphanumeric order로 순회합니다.\n",
    "    ## 빈 array에 np.concatenate로 numpy 배열 붙여나가는 방식으로 labeling 했습니다.\n",
    "    label_validation = np.array([], dtype ='int32')\n",
    "    for idx in sort(wheel_imgs_num.keys()):\n",
    "        x = np.array([idx]*wheel_imgs_num[idx], dtype ='int32') ## [카테고리 번호]를 카테고리 속하는 이미지 갯수만큼 배열 만들기\n",
    "        label_validation = np.concatenate((label_validation,x)) ## 배열 붙이기\n",
    "\n",
    "    del wheel_imgs_num\n",
    "    del wheel_img_path\n",
    "    del x\n",
    "\n",
    "    def result(img,model):\n",
    "        x = resize(img,(224,224))*255\n",
    "        x = preprocess_input(x)\n",
    "        x = np.expand_dims(x,0)\n",
    "        y = model.predict(x)\n",
    "        y = np.mean(y, axis=(1,2))\n",
    "        return y\n",
    "\n",
    "    validation_img_array = np.zeros((len(label_validation),2048))\n",
    "    pathes = glob.glob(\"C:/Users/seohyeonpark/프로젝트/augmented_validation2/*\")\n",
    "    sorted_pathes = sort(pathes)\n",
    "    del pathes\n",
    "    for folder_path in sorted_pathes:\n",
    "        img_pathes = glob.glob(folder_path+\"/*.jpeg\")\n",
    "        for i in range(len(img_pathes)):\n",
    "            img = Image.open(img_pathes[i])\n",
    "            img_numpy = np.array(img)\n",
    "            img_vector = result(img_numpy,model)\n",
    "            train_img_array[i] = img_vector\n",
    "            del img\n",
    "            del img_numpy\n",
    "            del img_vector\n",
    "        print(folder_path+\"is done.\")\n",
    "\n",
    "    np.save('C:/Users/seohyeonpark/프로젝트/feature vector/bottleneck_features_validation.npy', validation_img_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Data_augmentation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
