{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GlYQGKif1T4h"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "from PIL import Image\n",
    "from numpy import expand_dims\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 이진화 전처리 함수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "세웅이 모델에 들어가는 이미지 형태는 최종 BGR이여야 함!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1, 원본 그대로~\n",
    "def original(imgpath):\n",
    "    img = load_img(img_path)\n",
    "    img_array = img_to_array(img)\n",
    "    bgr_image = cv2.cvtColor(img_array,cv2.COLOR_RGB2BGR)\n",
    "    return bgr_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adaptive threshold만 적용\n",
    "def threshold(imgpath):\n",
    "    # grayscale 변환\n",
    "    img = load_img(imgpath)\n",
    "    img = img_to_array(img)\n",
    "    gray_image = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY) #(a,b) -> 2차원으로 변환\n",
    "    gray_image = gray_image.astype('uint8')\n",
    "    \n",
    "    # adaptive threshold 적용\n",
    "    th = cv2.adaptiveThreshold(gray_image,\n",
    "                               255,\n",
    "                               cv2.ADAPTIVE_THRESH_GAUSSIAN_C, \n",
    "                               cv2.THRESH_BINARY,\n",
    "                               99,\n",
    "                               15)\n",
    "    \n",
    "    # bgr 변환\n",
    "    bgr_image = cv2.cvtColor(th,cv2.COLOR_GRAY2BGR)\n",
    "    return bgr_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# morph gradient\n",
    "def morphology(imgpath):\n",
    "    # grayscale 변환\n",
    "    img = load_img(imgpath)\n",
    "    img = img_to_array(img)\n",
    "    gray_image = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY) #(a,b) -> 2차원으로 변환\n",
    "    gray_image = gray_image.astype('uint8')\n",
    "    \n",
    "    # morphgradient 적용\n",
    "    kernel = np.ones((2,2), np.uint8)\n",
    "    img_grad = cv2.morphologyEx(gray_image, cv2.MORPH_GRADIENT, kernel)\n",
    "    \n",
    "    # bgr로 변환\n",
    "    bgr_image = cv2.cvtColor(img_grad,cv2.COLOR_GRAY2BGR)\n",
    "    return bgr_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 대비 향상 -> adaptive threshold\n",
    "def threshold_sole(imgpath):\n",
    "    # grayscale 변환\n",
    "    img = load_img(imgpath)\n",
    "    img = img_to_array(img)\n",
    "    gray_image = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY) #(a,b) -> 2차원으로 변환\n",
    "    gray_image = gray_image.astype('uint8')\n",
    "    \n",
    "    # 이미지 대비를 향상\n",
    "    image_enhanced = cv2.equalizeHist(gray_image)\n",
    "    \n",
    "    # Adaptive Thresholding 적용 \n",
    "    max_output_value = 255   # 출력 픽셀 강도의 최대값\n",
    "    neighborhood_size = 99\n",
    "    subtract_from_mean = 15\n",
    "    image_binarized = cv2.adaptiveThreshold(image_enhanced,\n",
    "                                          255,\n",
    "                                          cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                          cv2.THRESH_BINARY,\n",
    "                                          99,\n",
    "                                          15)\n",
    "    \n",
    "    # bgr 변환\n",
    "    bgr_image = cv2.cvtColor(image_binarized,cv2.COLOR_GRAY2BGR)  \n",
    "    return bgr_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# morphology -> adaptive threshold\n",
    "def morph_threshold(imgpath):\n",
    "    # graysacle\n",
    "    img = load_img(imgpath)\n",
    "    img = img_to_array(img)\n",
    "    gray_image = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    gray_image = gray_image.astype('uint8')\n",
    "    \n",
    "    # morph gradient\n",
    "    kernel = np.ones((2,2), np.uint8)\n",
    "    img2_grad = cv2.morphologyEx(gray_image, cv2.MORPH_GRADIENT, kernel)\n",
    "    \n",
    "    # adaptive threshold\n",
    "    th = cv2.adaptiveThreshold(img2_grad, \n",
    "                               255, \n",
    "                               cv2.ADAPTIVE_THRESH_GAUSSIAN_C, \n",
    "                               cv2.THRESH_BINARY,\n",
    "                               99,\n",
    "                               15)\n",
    "    \n",
    "    # bgr 변환\n",
    "    bgr_image = cv2.cvtColor(th,cv2.COLOR_GRAY2BGR) # result함수 돌리기 위해 3차원으로 변환 \n",
    "    return bgr_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# morph_gradient -> 이미지 대비 향상 -> adaptive threshold\n",
    "def morph_threshold_sole(imgpath):\n",
    "    #grayscale\n",
    "    img = load_img(imgpath)\n",
    "    img = img_to_array(img)\n",
    "    gray_image = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    gray_image = gray_image.astype('uint8')\n",
    "    \n",
    "    # 이미지 대비를 향상\n",
    "    image_enhanced = cv2.equalizeHist(gray_image)\n",
    "    \n",
    "    # morph_gradient\n",
    "    kernel = np.ones((2,2), np.uint8)\n",
    "    img2_grad = cv2.morphologyEx(image_enhanced, cv2.MORPH_GRADIENT, kernel)\n",
    "    \n",
    "    # Adaptive Thresholding 적용 \n",
    "    image_binarized = cv2.adaptiveThreshold(img2_grad,\n",
    "                                          255,\n",
    "                                          cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                          cv2.THRESH_BINARY,\n",
    "                                          99,\n",
    "                                          15)\n",
    "    \n",
    "    # bgr 변환\n",
    "    bgr_image = cv2.cvtColor(image_binarized,cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    \n",
    "    return bgr_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 원본 이미지 경로 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_img_pathes = glob.glob(\"C:/Users/seohyeonpark/프로젝트/TuningStar/*.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:/Users/seohyeonpark/프로젝트/TuningStar\\\\0 (1).jpg',\n",
       " 'C:/Users/seohyeonpark/프로젝트/TuningStar\\\\0 (2).jpg',\n",
       " 'C:/Users/seohyeonpark/프로젝트/TuningStar\\\\0 (3).jpg',\n",
       " 'C:/Users/seohyeonpark/프로젝트/TuningStar\\\\1 (1).jpg',\n",
       " 'C:/Users/seohyeonpark/프로젝트/TuningStar\\\\1 (2).jpg']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 경로 확인\n",
    "my_img_pathes[:5] # '서현' 로컬 컴퓨터에서는 주소 마지막에 \\\\ 뜸.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 주소 정상적으로 불러지면 이 셀은 건너 뛰어도 됨\n",
    "i = 0\n",
    "for path in my_img_pathes:\n",
    "    path = path.replace('\\\\','/')\n",
    "    my_img_pathes[i] = path\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:/Users/seohyeonpark/프로젝트/TuningStar/0 (1).jpg',\n",
       " 'C:/Users/seohyeonpark/프로젝트/TuningStar/0 (2).jpg',\n",
       " 'C:/Users/seohyeonpark/프로젝트/TuningStar/0 (3).jpg',\n",
       " 'C:/Users/seohyeonpark/프로젝트/TuningStar/1 (1).jpg',\n",
       " 'C:/Users/seohyeonpark/프로젝트/TuningStar/1 (2).jpg']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_img_pathes[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 분류할 카테고리 넘버 리스트, 딕셔너리 만들기\n",
    "#### category_nums, category_count_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4RrVCjcM6Oe2"
   },
   "outputs": [],
   "source": [
    "category_nums=[]\n",
    "for img_path in my_img_pathes:\n",
    "    num_jpg = img_path.split(\"/\")[-1] # 휠 파일 이름.jpg\n",
    "    category_num = num_jpg.split('.')[0] # jpg 떼어 버리기!\n",
    "    try:\n",
    "        category_num = int(category_num) # (i)번 째 안되어 있으면 바로 정수형으로 바꿔잇!\n",
    "    except:\n",
    "        if \"(\" in category_num: # (i)번째 표시되어있으면 날리고 앞에 카테고리만 저장\n",
    "            category_num = int(category_num.split(\"(\")[0])\n",
    "        elif \"-\" in category_num: # - i 로 표시한 사람것도 날리고 앞에 카테고리만 저장\n",
    "            category_num = int(category_num.split('-')[0])\n",
    "    category_nums.append(category_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2Dt2HwB_SHFn"
   },
   "source": [
    "각 카테고리 번호 별로 몇 개씩 들어있는 지 카운팅한 뒤, 카테고리(key):등장횟수(value) 형태로 딕셔너리 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R8TDl9w2_GXI"
   },
   "outputs": [],
   "source": [
    "category_count_dict = {}\n",
    "for i in range(len(category_nums)):\n",
    "    num_count = category_nums.count(i)\n",
    "    category_count_dict[i] = num_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([3, 2, 2, 1, 3, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 2, 1, 6, 1, 2, 1, 4, 1, 1, 1, 1, 4, 2, 1, 5, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 3, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 3, 3, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 4, 1, 1, 1, 3, 1, 9, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 2, 2, 1, 7, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 4, 8, 1, 1, 7, 3, 1, 2, 1, 1, 1, 1, 1, 2, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3, 1, 1, 2, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 10, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 3, 4, 4, 2, 4, 7, 3, 2, 2, 3, 3, 6, 2, 2, 2, 2, 3, 2, 3, 2, 2, 2, 2, 2, 6, 4, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value = category_count_dict.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_list = []\n",
    "for value in category_count_dict.values():\n",
    "    if value not in count_list:\n",
    "        count_list.append(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 2, 1, 6, 4, 5, 9, 7, 8, 10, 0]\n"
     ]
    }
   ],
   "source": [
    "print(count_list) # 2, 3, 5, 7 -> 2100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5Ux2t2mqSAI2"
   },
   "source": [
    "Keras의 ImageDataGenerator를 통해 Data Augmentation을 할 수 있는 generator생성."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qxGJA1qa1fQx"
   },
   "outputs": [],
   "source": [
    "## data augmentation\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "##ImageDataGenerator에 원하는 옵션들을 추가해주면 옵션들 적용하면서 랜덤하게 생성해줍니다.\n",
    "datagen = ImageDataGenerator(\n",
    "        rotation_range = 90,\n",
    "        width_shift_range = 0.2,\n",
    "        height_shift_range = 0.2,\n",
    "        brightness_range = [0.05 , 2.0],\n",
    "        vertical_flip = True,\n",
    "        horizontal_flip = True,\n",
    "        fill_mode= 'nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 각 전처리 방법으로 이진화 후 다른 폴더에 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C8v-ISjqSZv1"
   },
   "source": [
    "배정받은 이미지 경로들을 통해 이미지를 가져오고,\n",
    "하나의 카테고리를 하나의 폴더로 만듦. 위에서도 이야기했듯이 파일 번호 = 카테고리이므로 이미 카테고리 폴더가 생성되어있는 경우는 넘어가게 햇음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하나의 이미지에 대해 파일 이름, 카테고리 인덱스, 같은 카테고리로 분류된 이미지의 개수 반환해주는 함수\n",
    "def count_category(img_path, category_count_dict):\n",
    "    # 1. 파일 이름(img_name)\n",
    "    num_jpg = img_path.split(\"/\")[-1] # 이미지 경로 마지막 (휠 번호.jpg) 만 떼어내기\n",
    "    category_num = num_jpg.split('.')[0] # .jpg떼어 버리기! (휠 번호.jpg) -> (휠 번호)\n",
    "    img_name = category_num\n",
    "    \n",
    "    # 2. 카테고리 인덱스(category_num)\n",
    "    try:\n",
    "        '''\n",
    "        카테고리 번호만 category_num에 저장하도록 한다 -> 나중에 augmentation한 폴더 이름 설정할 때 사용\n",
    "        현재 img_name은 1 or 1 (1) or 1-1 형식으로 되어있음.\n",
    "        맨 앞에 카테고리 분류한 숫자에만 관심이 있기 때문에\n",
    "        먼저 1과 같이 같은 카테고리 내에 한 개의 이미지만 있는 경우는 int(category_num)으로 숫자 추출,\n",
    "        에러가 발생한다면 \"(\", \")\",\"-\" 등이 category_num에 포함되어 있는 것이기 때문에,\n",
    "        각 문장부호 들로 split 후 맨 앞에 카테고리 분류 숫자를 반환\n",
    "        '''\n",
    "        category_num = int(category_num) # (i)번 째 안되어 있으면 바로 정수형으로 바꿔잇!\n",
    "    except:\n",
    "        if \"(\" in category_num: # (i)번째 표시되어있으면 날리고 앞에 카테고리만 저장\n",
    "            category_num = int(category_num.split(\"(\")[0])\n",
    "        elif \"-\" in category_num: # - i 로 표시한 사람것도 날리고 앞에 카테고리만 저장\n",
    "            category_num = int(category_num.split('-')[0])\n",
    "    \n",
    "    # 3. 같은 카테고리로 분류된 이미지의 개수(category_count)\n",
    "    category_count = category_count_dict[category_num] # 해당 이미지의 카테고리에 몇개의 이미지가 있는가\n",
    "    return img_name, category_count, category_num\n",
    "\n",
    "# 이미지 전처리 함수\n",
    "#: 앞서 정해준 이진화 방법들 중 하나를 function에 넣어주면 이미지를 해당 방법으로 이진화 후 \n",
    "def preprocess(img_path, function):\n",
    "    img = function(img_path) # function에 전처리 함수를 넣어 해당 방법으로 전처리한다.\n",
    "    x = expand_dims(img,0) # 차원 추가\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 478
    },
    "colab_type": "code",
    "id": "gz_D3luq9Pyr",
    "outputId": "88cdd47b-d578-4b8c-84d5-2e03f5807633",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "106\n",
      "106\n",
      "106\n",
      "106\n",
      "106\n",
      "106\n",
      "106\n",
      "106\n",
      "106\n",
      "106\n",
      "106\n",
      "106\n",
      "106\n",
      "106\n",
      "106\n",
      "106\n",
      "106\n",
      "106\n",
      "106\n",
      "106\n",
      "106\n",
      "106\n",
      "106\n",
      "106\n",
      "106\n",
      "106\n",
      "106\n",
      "106\n",
      "106\n",
      "106\n",
      "106\n",
      "106\n",
      "106\n",
      "106\n",
      "106\n",
      "106\n",
      "106\n",
      "106\n",
      "106\n",
      "106\n",
      "106\n",
      "106\n",
      "106\n",
      "106\n",
      "106\n",
      "106\n",
      "106\n",
      "106\n",
      "106\n",
      "106\n",
      "106\n",
      "106\n",
      "106\n",
      "106\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-151-a3dfa1712f79>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfolder_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m             \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfolder_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdatagen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_to_dir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfolder_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_prefix\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"jpeg\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m             \u001b[0mj\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mj\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mimg_num\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\iterator.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 104\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    105\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\iterator.py\u001b[0m in \u001b[0;36mnext\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    114\u001b[0m         \u001b[1;31m# The transformation of images is not under thread lock\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m         \u001b[1;31m# so it can be done in parallel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 116\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_batches_of_transformed_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex_array\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    117\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_batches_of_transformed_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex_array\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\numpy_array_iterator.py\u001b[0m in \u001b[0;36m_get_batches_of_transformed_samples\u001b[1;34m(self, index_array)\u001b[0m\n\u001b[0;32m    151\u001b[0m             \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage_data_generator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_random_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m             x = self.image_data_generator.apply_transform(\n\u001b[1;32m--> 153\u001b[1;33m                 x.astype(self.dtype), params)\n\u001b[0m\u001b[0;32m    154\u001b[0m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage_data_generator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstandardize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m             \u001b[0mbatch_x\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\image_data_generator.py\u001b[0m in \u001b[0;36mapply_transform\u001b[1;34m(self, x, transform_parameters)\u001b[0m\n\u001b[0;32m    868\u001b[0m                                    \u001b[0mfill_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfill_mode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    869\u001b[0m                                    \u001b[0mcval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 870\u001b[1;33m                                    order=self.interpolation_order)\n\u001b[0m\u001b[0;32m    871\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    872\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtransform_parameters\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'channel_shift_intensity'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\affine_transformations.py\u001b[0m in \u001b[0;36mapply_affine_transform\u001b[1;34m(x, theta, tx, ty, shear, zx, zy, row_axis, col_axis, channel_axis, fill_mode, cval, order)\u001b[0m\n\u001b[0;32m    331\u001b[0m             \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    332\u001b[0m             \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfill_mode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 333\u001b[1;33m             cval=cval) for x_channel in x]\n\u001b[0m\u001b[0;32m    334\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchannel_images\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    335\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrollaxis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchannel_axis\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\affine_transformations.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    331\u001b[0m             \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    332\u001b[0m             \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfill_mode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 333\u001b[1;33m             cval=cval) for x_channel in x]\n\u001b[0m\u001b[0;32m    334\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchannel_images\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    335\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrollaxis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchannel_axis\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\ndimage\\interpolation.py\u001b[0m in \u001b[0;36maffine_transform\u001b[1;34m(input, matrix, offset, output_shape, output, order, mode, cval, prefilter)\u001b[0m\n\u001b[0;32m    484\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    485\u001b[0m         _nd_image.geometric_transform(filtered, None, None, matrix, offset,\n\u001b[1;32m--> 486\u001b[1;33m                                       output, order, mode, cval, None, None)\n\u001b[0m\u001b[0;32m    487\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# j == 14 도  j/category_count로 들어가야 할 듯\n",
    "# 원본이미지로만 구성된 validation set도 만들기\n",
    "# \n",
    "\n",
    "''' 전처리 함수 메뉴\n",
    "1. original : 원본 이미지\n",
    "2. threshold : Adaptive만 적용\n",
    "3. morphology : morph gradient만 적용\n",
    "4. threshold_sole : 이미지 대비 향상 -> Adaptive\n",
    "5. morph_threshold : morph gradient -> Adaptive \n",
    "6. morph_threshold_sole : 이미지 대비 향상 morph gradient -> adaptive threshold \n",
    "'''\n",
    "\n",
    "# 전처리 함수 리스트\n",
    "functions = [original,\n",
    "             threshold,\n",
    "             #morphology, (정확하게는 이진화하는 방법이 아니라 사용하지 않아도 될 듯?)\n",
    "             threshold_sole,\n",
    "             morph_threshold,\n",
    "             morph_threshold_sole]\n",
    "\n",
    "for img_path in my_img_pathes:\n",
    "    \n",
    "    ''' category별 개수 구하기 '''\n",
    "    img_name, category_count, category_num = count_category(img_path, category_count_dict)\n",
    "    \n",
    "    ''' 전처리 '''\n",
    "    i = 1\n",
    "    for function in functions:\n",
    "        x = preprocess(img_path, function)\n",
    "        \n",
    "        img_num = 1500 # int(10000/category_count)\n",
    "        aug_num = int(img_num/category_count)\n",
    "        \n",
    "        if img_num%category_count != 0: # 여기서 print의 결과로 나오는 이미지들은 10000의 약수가 아니므로, augmentation한 결과가 정확히 10000장이 되지 못함. 해당 카테고리에서는 수동으로 이미지 복붙해서 10000장 맞춰주세요.\n",
    "            print(category_num)\n",
    "        \n",
    "        # 각 카테고리 별로 augmentation 이미지 14개 씩 validation 폴더에 저장\n",
    "        j=0\n",
    "        \n",
    "        # 아래 폴더 이름은 \"C:/Users/seohyeonpark/프로젝트\" 부분만 원하는 경로로 바꿔주세요. \n",
    "        validation_folder = \"C:/Users/seohyeonpark/프로젝트/Validation_\" + str(i) + \"/\" + str(category_num)\n",
    "        if not(os.path.isdir(validation_folder)):\n",
    "            os.makedirs(validation_folder)\n",
    "        for batch in datagen.flow(x, batch_size=32, save_to_dir=validation_folder, save_prefix=j, save_format=\"jpeg\"):\n",
    "            j+=1\n",
    "            if j == 14:\n",
    "                break\n",
    "\n",
    "        # 14개 이후에는 augmentation 폴더에 저장\n",
    "        # 아래 폴더 이름은 \"C:/Users/seohyeonpark/프로젝트\" 부분만 원하는 경로로 바꿔주세요. \n",
    "        folder_path = \"C:/Users/seohyeonpark/프로젝트/Data Augmentation_\" + str(i) + \"/\" + str(category_num) # folder_path는 자기가 저장할 경로에 맞게 수정해주어야 함. str(category)는 건들지 말고 앞부분만 수정.\n",
    "        if not(os.path.isdir(folder_path)):\n",
    "            os.makedirs(folder_path)\n",
    "        for batch in datagen.flow(x, batch_size=32, save_to_dir=folder_path, save_prefix=j, save_format=\"jpeg\"):\n",
    "            j+=1\n",
    "            if j > aug_num:\n",
    "                break\n",
    "                \n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 이후에는 세웅이 모델 학습 붙이기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\seohyeonpark\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\seohyeonpark\\Anaconda3\\lib\\site-packages\\keras_applications\\resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94658560/94653016 [==============================] - 89s 1us/step\n",
      "Found 48266 images belonging to 756 classes.\n",
      "WARNING:tensorflow:From C:\\Users\\seohyeonpark\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-76-480ad6d1530c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m   shuffle=False)\n\u001b[0;32m     17\u001b[0m bottleneck_features_train = model.predict_generator(\n\u001b[1;32m---> 18\u001b[1;33m   generator)\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;31m# np.save / np.load : 경로 지정한 곳으로 저장, 불러오기 가능, .npy확장자로 save하면 batch로 묶인 벡터들이 들어간다.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m np.save('C:/Users/seohyeonpark/프로젝트/feature vector/bottleneck_features_train.npy',\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict_generator\u001b[1;34m(self, generator, steps, callbacks, max_queue_size, workers, use_multiprocessing, verbose)\u001b[0m\n\u001b[0;32m   1844\u001b[0m             \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1845\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1846\u001b[1;33m             verbose=verbose)\n\u001b[0m\u001b[0;32m   1847\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1848\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mpredict_generator\u001b[1;34m(model, generator, steps, callbacks, max_queue_size, workers, use_multiprocessing, verbose)\u001b[0m\n\u001b[0;32m    525\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'predict'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'begin'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps_done\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    526\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 527\u001b[1;33m             \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    528\u001b[0m             \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    529\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict_on_batch\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m   1578\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1579\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_predict_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1580\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1581\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1582\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[1;32m-> 3292\u001b[1;33m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[0;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1458\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1459\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "'''\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import applications\n",
    "\n",
    "img_width, img_height = 224, 224 ##프로젝트 활용 이미지의 크기\n",
    "train_data_dir = 'C:/Users/seohyeonpark/프로젝트/Data Augmentation'\n",
    "datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "batch_size = 10\n",
    "# build the ResNet50 Network\n",
    "model = applications.ResNet50(include_top=False, weights='imagenet')\n",
    "# Shuffle을 false로 두어야 원래 순서대로 들어감(카테고리가 뒤섞이지 않는다.)\n",
    "generator = datagen.flow_from_directory(\n",
    "  train_data_dir,\n",
    "  target_size=(img_width, img_height),\n",
    "  batch_size=batch_size,\n",
    "  class_mode=None,\n",
    "  shuffle=False)\n",
    "bottleneck_features_train = model.predict_generator(\n",
    "  generator)`\n",
    "# np.save / np.load : 경로 지정한 곳으로 저장, 불러오기 가능, .npy확장자로 save하면 batch로 묶인 벡터들이 들어간다.\n",
    "np.save('C:/Users/seohyeonpark/프로젝트/feature vector/bottleneck_features_train.npy',\n",
    "      bottleneck_features_train)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Data_augmentation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
